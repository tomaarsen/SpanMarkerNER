<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>SpanMarker :: Getting Started with SpanMarker</title>
  
  <link rel="index" title="Index" href="../genindex.html"/>

  <link rel="stylesheet" href="../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../index.html">SpanMarker</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Notebooks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_training.html">Initializing &amp; Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_loading.html">Loading &amp; Inferencing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_configuration.html">Configuring</a></li>
<li class="toctree-l2"><a class="reference internal" href="spacy_integration.html">SpanMarker with spaCy</a></li>
<li class="toctree-l2"><a class="reference internal" href="document_level_context.html">Document-level context</a></li>
<li class="toctree-l2"><a class="reference external" href="https://raw.githubusercontent.com/tomaarsen/SpanMarkerNER/main/thesis.pdf">SpanMarker Thesis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/span_marker.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.modeling.html">span_marker.modeling module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.trainer.html">span_marker.trainer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.configuration.html">span_marker.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.model_card.html">span_marker.model_card module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.pipeline_component.html">span_marker.pipeline_component module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.data_collator.html">span_marker.data_collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.tokenizer.html">span_marker.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.evaluation.html">span_marker.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.label_normalizer.html">span_marker.label_normalizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.output.html">span_marker.output module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.spacy_integration.html">span_marker.spacy_integration module</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing SpanMarker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker on GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://huggingface.co/models?library=span-marker">SpanMarker on the ü§ó Hub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://spacy.io/universe/project/span_marker">SpanMarker on spaCy</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <div class="open-in-colab__wrapper">
<a href="https://colab.research.google.com/github/tomaarsen/SpanMarkerNER/blob/main/notebooks/getting_started.ipynb" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" style="display: inline; margin: 0" alt="Open In Colab"/>
</a>
</div><section id="Getting-Started-with-SpanMarker">
<h1>Getting Started with SpanMarker<a class="headerlink" href="#Getting-Started-with-SpanMarker" title="Link to this heading">¬∂</a></h1>
<p><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker</a> is an accessible yet powerful Python module for training Named Entity Recognition models.</p>
<p>In this notebook, we‚Äôll have a look at how to train an NER model using SpanMarker.</p>
<section id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Link to this heading">¬∂</a></h2>
<p>First of all, the <code class="docutils literal notranslate"><span class="pre">span_marker</span></code> Python module needs to be installed. If we want to use <a class="reference external" href="https://wandb.ai/">Weights and Biases</a> for logging, we can install <code class="docutils literal notranslate"><span class="pre">span_marker</span></code> using the <code class="docutils literal notranslate"><span class="pre">[wandb]</span></code> extra.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install span_marker
<span class="c1"># %pip install span_marker[wandb]</span>
</pre></div>
</div>
</div>
</section>
<section id="Loading-the-dataset">
<h2>Loading the dataset<a class="headerlink" href="#Loading-the-dataset" title="Link to this heading">¬∂</a></h2>
<p>For this example, we‚Äôll load the challenging <a class="reference external" href="https://huggingface.co/datasets/DFKI-SLT/few-nerd">FewNERD supervised dataset</a> from the Hugging Face hub using ü§ó Datasets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">dataset_id</span> <span class="o">=</span> <span class="s2">&quot;DFKI-SLT/few-nerd&quot;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_id</span><span class="p">,</span> <span class="s2">&quot;supervised&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DatasetDict({
    train: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 131767
    })
    validation: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 18824
    })
    test: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 37648
    })
})
</pre></div></div>
</div>
<p>Let‚Äôs inspect some samples to get a feel for the data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;id&#39;: &#39;0&#39;, &#39;tokens&#39;: [&#39;Paul&#39;, &#39;International&#39;, &#39;airport&#39;, &#39;.&#39;], &#39;ner_tags&#39;: [0, 0, 0, 0], &#39;fine_ner_tags&#39;: [0, 0, 0, 0]}
{&#39;id&#39;: &#39;1&#39;, &#39;tokens&#39;: [&#39;It&#39;, &#39;starred&#39;, &#39;Hicks&#39;, &#34;&#39;s&#34;, &#39;wife&#39;, &#39;,&#39;, &#39;Ellaline&#39;, &#39;Terriss&#39;, &#39;and&#39;, &#39;Edmund&#39;, &#39;Payne&#39;, &#39;.&#39;], &#39;ner_tags&#39;: [0, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 0], &#39;fine_ner_tags&#39;: [0, 0, 51, 0, 0, 0, 50, 50, 0, 50, 50, 0]}
{&#39;id&#39;: &#39;2&#39;, &#39;tokens&#39;: [&#39;``&#39;, &#39;Time&#39;, &#39;``&#39;, &#39;magazine&#39;, &#39;said&#39;, &#39;the&#39;, &#39;film&#39;, &#39;was&#39;, &#39;``&#39;, &#39;a&#39;, &#39;multimillion&#39;, &#39;dollar&#39;, &#39;improvisation&#39;, &#39;that&#39;, &#39;does&#39;, &#39;everything&#39;, &#39;but&#39;, &#39;what&#39;, &#39;the&#39;, &#39;title&#39;, &#39;promises&#39;, &#34;&#39;&#39;&#34;, &#39;and&#39;, &#39;suggested&#39;, &#39;that&#39;, &#39;``&#39;, &#39;writer&#39;, &#39;George&#39;, &#39;Axelrod&#39;, &#39;(&#39;, &#39;``&#39;, &#39;The&#39;, &#39;Seven&#39;, &#39;Year&#39;, &#39;Itch&#39;, &#39;``&#39;, &#39;)&#39;, &#39;and&#39;, &#39;director&#39;, &#39;Richard&#39;, &#39;Quine&#39;, &#39;should&#39;, &#39;have&#39;, &#39;taken&#39;, &#39;a&#39;, &#39;hint&#39;, &#39;from&#39;, &#39;Holden&#39;, &#39;[&#39;, &#34;&#39;s&#34;, &#39;character&#39;, &#39;Richard&#39;, &#39;Benson&#39;, &#39;]&#39;, &#39;,&#39;, &#39;who&#39;, &#39;writes&#39;, &#39;his&#39;, &#39;movie&#39;, &#39;,&#39;, &#39;takes&#39;, &#39;a&#39;, &#39;long&#39;, &#39;sober&#39;, &#39;look&#39;, &#39;at&#39;, &#39;what&#39;, &#39;he&#39;, &#39;has&#39;, &#39;wrought&#39;, &#39;,&#39;, &#39;and&#39;, &#39;burns&#39;, &#39;it&#39;, &#39;.&#39;, &#34;&#39;&#39;&#34;], &#39;ner_tags&#39;: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;fine_ner_tags&#39;: [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 51, 0, 0, 6, 6, 6, 6, 0, 0, 0, 0, 53, 53, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
</pre></div></div>
</div>
<p>As you can see, this dataset contains <code class="docutils literal notranslate"><span class="pre">tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> and a <code class="docutils literal notranslate"><span class="pre">fine_ner_tags</span></code> columns. Let‚Äôs have a look at which labels these last two represent using the <a class="reference external" href="https://huggingface.co/docs/datasets/about_dataset_features">Dataset features</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;O&#39;, &#39;art&#39;, &#39;building&#39;, &#39;event&#39;, &#39;location&#39;, &#39;organization&#39;, &#39;other&#39;, &#39;person&#39;, &#39;product&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fine_labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;fine_ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fine_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;O&#39;, &#39;art-broadcastprogram&#39;, &#39;art-film&#39;, &#39;art-music&#39;, &#39;art-other&#39;, &#39;art-painting&#39;, &#39;art-writtenart&#39;, &#39;building-airport&#39;, &#39;building-hospital&#39;, &#39;building-hotel&#39;, &#39;building-library&#39;, &#39;building-other&#39;, &#39;building-restaurant&#39;, &#39;building-sportsfacility&#39;, &#39;building-theater&#39;, &#39;event-attack/battle/war/militaryconflict&#39;, &#39;event-disaster&#39;, &#39;event-election&#39;, &#39;event-other&#39;, &#39;event-protest&#39;, &#39;event-sportsevent&#39;, &#39;location-GPE&#39;, &#39;location-bodiesofwater&#39;, &#39;location-island&#39;, &#39;location-mountain&#39;, &#39;location-other&#39;, &#39;location-park&#39;, &#39;location-road/railway/highway/transit&#39;, &#39;organization-company&#39;, &#39;organization-education&#39;, &#39;organization-government/governmentagency&#39;, &#39;organization-media/newspaper&#39;, &#39;organization-other&#39;, &#39;organization-politicalparty&#39;, &#39;organization-religion&#39;, &#39;organization-showorganization&#39;, &#39;organization-sportsleague&#39;, &#39;organization-sportsteam&#39;, &#39;other-astronomything&#39;, &#39;other-award&#39;, &#39;other-biologything&#39;, &#39;other-chemicalthing&#39;, &#39;other-currency&#39;, &#39;other-disease&#39;, &#39;other-educationaldegree&#39;, &#39;other-god&#39;, &#39;other-language&#39;, &#39;other-law&#39;, &#39;other-livingthing&#39;, &#39;other-medical&#39;, &#39;person-actor&#39;, &#39;person-artist/author&#39;, &#39;person-athlete&#39;, &#39;person-director&#39;, &#39;person-other&#39;, &#39;person-politician&#39;, &#39;person-scholar&#39;, &#39;person-soldier&#39;, &#39;product-airplane&#39;, &#39;product-car&#39;, &#39;product-food&#39;, &#39;product-game&#39;, &#39;product-other&#39;, &#39;product-ship&#39;, &#39;product-software&#39;, &#39;product-train&#39;, &#39;product-weapon&#39;]
</pre></div></div>
</div>
<p>For the purposes of this tutorial, let‚Äôs stick with the <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> coarse-grained labels, but I challenge you to modify this Notebook to train for the fine labels. For the SpanMarker model, any dataset can be used as long as it has a <code class="docutils literal notranslate"><span class="pre">tokens</span></code> and a <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> column. The <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> can be annotated using the IOB, IOB2, BIOES or BILOU labeling scheme, but also regular unschemed labels like in this FewNERD example can be used.</p>
</section>
<section id="Initializing-a-SpanMarkerModel">
<h2>Initializing a <code class="docutils literal notranslate"><span class="pre">SpanMarkerModel</span></code><a class="headerlink" href="#Initializing-a-SpanMarkerModel" title="Link to this heading">¬∂</a></h2>
<p>A SpanMarker model is initialized via <a class="reference external" href="https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.from_pretrained">SpanMarkerModel.from_pretrained</a>. This method will be familiar to those who know ü§ó Transformers. It accepts either a path to a local model or the name of a model on the <a class="reference external" href="https://huggingface.co/models">Hugging Face Hub</a>.</p>
<p>Importantly, the model can <em>either</em> be an encoder or an already trained and saved SpanMarker model. As we haven‚Äôt trained anything yet, we will use an encoder. To learn how to load and use a saved SpanMarker model, please have a look at the <a class="reference internal" href="model_loading.html"><span class="doc">Loading &amp; Inferencing</span></a> notebook.</p>
<p>Reasonable options for encoders include BERT, RoBERTa, mBERT, XLM-RoBERTa, etc., which means that the following are all good options:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/prajjwal1/bert-tiny">prajjwal1/bert-tiny</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/prajjwal1/bert-mini">prajjwal1/bert-mini</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/prajjwal1/bert-small">prajjwal1/bert-small</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/prajjwal1/bert-medium">prajjwal1/bert-medium</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/bert-base-cased">bert-base-cased</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/bert-large-cased">bert-large-cased</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/bert-base-multilingual-cased">bert-base-multilingual-cased</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/bert-base-multilingual-uncased">bert-base-multilingual-uncased</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/roberta-base">roberta-base</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/roberta-large">roberta-large</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/xlm-roberta-base">xlm-roberta-base</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/xlm-roberta-large">xlm-roberta-large</a></p></li>
</ul>
<p>Not all encoders work though, they <strong>must</strong> allow for <code class="docutils literal notranslate"><span class="pre">position_ids</span></code> as an input argument, which disqualifies DistilBERT, T5, DistilRoBERTa, ALBERT &amp; BART.</p>
<p>Additionally, it‚Äôs important to consider that cased models typically demand consistent capitalization in the inference data, aligning with how the training data is formatted. In simpler terms, if your training data consistently uses correct capitalization, but your inference data does not, it may lead to suboptimal performance. In such cases, you might find an uncased model more suitable. Although it may exhibit slightly lower F1 scores on the testing set, it remains functional regardless of
capitalization, making it potentially more effective in real-world scenarios.</p>
<p>We‚Äôll use <code class="docutils literal notranslate"><span class="pre">&quot;bert-base-cased&quot;</span></code> for this notebook. If you‚Äôre running this on Google Colab, be sure to set hardware accelerator to ‚ÄúGPU‚Äù in <code class="docutils literal notranslate"><span class="pre">Runtime</span></code> &gt; <code class="docutils literal notranslate"><span class="pre">Change</span> <span class="pre">runtime</span> <span class="pre">type</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">SpanMarkerModel</span><span class="p">,</span> <span class="n">SpanMarkerModelCardData</span>

<span class="n">encoder_id</span> <span class="o">=</span> <span class="s2">&quot;bert-base-cased&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="c1"># Required arguments</span>
    <span class="n">encoder_id</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="c1"># Optional arguments</span>
    <span class="n">model_max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">entity_max_length</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="c1"># To improve the generated model card</span>
    <span class="n">model_card_data</span><span class="o">=</span><span class="n">SpanMarkerModelCardData</span><span class="p">(</span>
        <span class="n">language</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;en&quot;</span><span class="p">],</span>
        <span class="n">license</span><span class="o">=</span><span class="s2">&quot;cc-by-sa-4.0&quot;</span><span class="p">,</span>
        <span class="n">encoder_id</span><span class="o">=</span><span class="n">encoder_id</span><span class="p">,</span>
        <span class="n">dataset_id</span><span class="o">=</span><span class="n">dataset_id</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>For us, these warnings are expected, as we are initializing <code class="docutils literal notranslate"><span class="pre">BertModel</span></code> for a new task.</p>
<p>Note that we provided <code class="docutils literal notranslate"><span class="pre">SpanMarkerModel.from_pretrained</span></code> with a list of our labels. This is required when training a new model using an encoder. Furthermore, we can specify some useful configuration parameters from <code class="docutils literal notranslate"><span class="pre">SpanMarkerConfig</span></code>, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_max_length</span></code>: The maximum number of tokens that the model will process. If you only use short sentences for your model, reducing this number may help training and inference speeds with no loss in performance. Defaults to the encoder maximum, or 512 if the encoder doesn‚Äôt have a maximum.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entity_max_length</span></code>: The total number of words that one entity can be. Defaults to 8.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_card_data</span></code>: A <a class="reference external" href="https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.model_card.html#span_marker.model_card.SpanMarkerModelCardData">SpanMarkerModelCardData</a> instance where you can provide a lot of useful data about your model. This data will be automatically included in a generated model card whenever a model is saved or pushed to the Hugging Face Hub.</p>
<ul>
<li><p>Consider adding <code class="docutils literal notranslate"><span class="pre">language</span></code>, <code class="docutils literal notranslate"><span class="pre">license</span></code>, <code class="docutils literal notranslate"><span class="pre">model_id</span></code>, <code class="docutils literal notranslate"><span class="pre">encoder_id</span></code> and <code class="docutils literal notranslate"><span class="pre">dataset_id</span></code> to improve the generated model card README.md file.</p></li>
</ul>
</li>
</ul>
</section>
<section id="Training">
<h2>Training<a class="headerlink" href="#Training" title="Link to this heading">¬∂</a></h2>
<p>At this point, our model is already ready for training! We can import <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> directly from ü§ó Transformers as well as the SpanMarker <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> is a subclass of the ü§ó Transformers <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer">Trainer</a> that simplifies some tasks for you, but otherwise it works just like the regular <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<p>This next snippet shows some reasonable defaults. Feel free to adjust the batch size to a lower value if you experience out of memory exceptions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">dataloader_num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we can create a SpanMarker <a class="reference external" href="https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.trainer.html#span_marker.trainer.Trainer">Trainer</a> in the same way that you would initialize a ü§ó Transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. We‚Äôll train on a subsection of the data to save us some time. Amazingly, this <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> will automatically create logs using exactly the logging tools that you have installed. With other words, if you prefer logging with <a class="reference external" href="https://www.tensorflow.org/tensorboard">Tensorboard</a>,
all that you have to do is install it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">8000</span><span class="p">)),</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let‚Äôs start training!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;loss&#39;: 0.6974, &#39;learning_rate&#39;: 1.991869918699187e-05, &#39;epoch&#39;: 0.04}
{&#39;loss&#39;: 0.0896, &#39;learning_rate&#39;: 4.0243902439024395e-05, &#39;epoch&#39;: 0.08}
{&#39;loss&#39;: 0.0584, &#39;learning_rate&#39;: 4.8822463768115946e-05, &#39;epoch&#39;: 0.12}
{&#39;loss&#39;: 0.0382, &#39;learning_rate&#39;: 4.655797101449276e-05, &#39;epoch&#39;: 0.16}
{&#39;eval_loss&#39;: 0.03181104362010956, &#39;eval_overall_precision&#39;: 0.6967930029154519, &#39;eval_overall_recall&#39;: 0.5989974937343359, &#39;eval_overall_f1&#39;: 0.6442048517520216, &#39;eval_overall_accuracy&#39;: 0.8993717106605198, &#39;eval_runtime&#39;: 29.16, &#39;eval_samples_per_second&#39;: 83.985, &#39;eval_steps_per_second&#39;: 21.022, &#39;epoch&#39;: 0.16}
{&#39;loss&#39;: 0.0333, &#39;learning_rate&#39;: 4.429347826086957e-05, &#39;epoch&#39;: 0.2}
{&#39;loss&#39;: 0.0303, &#39;learning_rate&#39;: 4.202898550724638e-05, &#39;epoch&#39;: 0.24}
{&#39;loss&#39;: 0.032, &#39;learning_rate&#39;: 3.976449275362319e-05, &#39;epoch&#39;: 0.29}
{&#39;loss&#39;: 0.0304, &#39;learning_rate&#39;: 3.7500000000000003e-05, &#39;epoch&#39;: 0.33}
{&#39;eval_loss&#39;: 0.02394717186689377, &#39;eval_overall_precision&#39;: 0.7350157728706624, &#39;eval_overall_recall&#39;: 0.7187198766146135, &#39;eval_overall_f1&#39;: 0.7267764889365436, &#39;eval_overall_accuracy&#39;: 0.9227489698502713, &#39;eval_runtime&#39;: 29.481, &#39;eval_samples_per_second&#39;: 83.07, &#39;eval_steps_per_second&#39;: 20.793, &#39;epoch&#39;: 0.33}
{&#39;loss&#39;: 0.0265, &#39;learning_rate&#39;: 3.5235507246376816e-05, &#39;epoch&#39;: 0.37}
{&#39;loss&#39;: 0.0254, &#39;learning_rate&#39;: 3.297101449275363e-05, &#39;epoch&#39;: 0.41}
{&#39;loss&#39;: 0.0249, &#39;learning_rate&#39;: 3.0706521739130435e-05, &#39;epoch&#39;: 0.45}
{&#39;loss&#39;: 0.0242, &#39;learning_rate&#39;: 2.8442028985507245e-05, &#39;epoch&#39;: 0.49}
{&#39;eval_loss&#39;: 0.02163967303931713, &#39;eval_overall_precision&#39;: 0.762808736476832, &#39;eval_overall_recall&#39;: 0.7204549836128783, &#39;eval_overall_f1&#39;: 0.7410271663692247, &#39;eval_overall_accuracy&#39;: 0.9293582473175309, &#39;eval_runtime&#39;: 29.0261, &#39;eval_samples_per_second&#39;: 84.372, &#39;eval_steps_per_second&#39;: 21.119, &#39;epoch&#39;: 0.49}
{&#39;loss&#39;: 0.0224, &#39;learning_rate&#39;: 2.6177536231884058e-05, &#39;epoch&#39;: 0.53}
{&#39;loss&#39;: 0.0242, &#39;learning_rate&#39;: 2.391304347826087e-05, &#39;epoch&#39;: 0.57}
{&#39;loss&#39;: 0.0226, &#39;learning_rate&#39;: 2.164855072463768e-05, &#39;epoch&#39;: 0.61}
{&#39;loss&#39;: 0.0245, &#39;learning_rate&#39;: 1.9384057971014493e-05, &#39;epoch&#39;: 0.65}
{&#39;eval_loss&#39;: 0.020556513220071793, &#39;eval_overall_precision&#39;: 0.7680876026593665, &#39;eval_overall_recall&#39;: 0.7572778099093889, &#39;eval_overall_f1&#39;: 0.7626444034559751, &#39;eval_overall_accuracy&#39;: 0.9338052303047611, &#39;eval_runtime&#39;: 29.7545, &#39;eval_samples_per_second&#39;: 82.307, &#39;eval_steps_per_second&#39;: 20.602, &#39;epoch&#39;: 0.65}
{&#39;loss&#39;: 0.0231, &#39;learning_rate&#39;: 1.7119565217391306e-05, &#39;epoch&#39;: 0.69}
{&#39;loss&#39;: 0.0209, &#39;learning_rate&#39;: 1.4855072463768116e-05, &#39;epoch&#39;: 0.73}
{&#39;loss&#39;: 0.0202, &#39;learning_rate&#39;: 1.2590579710144929e-05, &#39;epoch&#39;: 0.77}
{&#39;loss&#39;: 0.0212, &#39;learning_rate&#39;: 1.032608695652174e-05, &#39;epoch&#39;: 0.81}
{&#39;eval_loss&#39;: 0.01960749179124832, &#39;eval_overall_precision&#39;: 0.7743021183923976, &#39;eval_overall_recall&#39;: 0.7540003855793329, &#39;eval_overall_f1&#39;: 0.7640164094549716, &#39;eval_overall_accuracy&#39;: 0.9358247317530904, &#39;eval_runtime&#39;: 29.6794, &#39;eval_samples_per_second&#39;: 82.515, &#39;eval_steps_per_second&#39;: 20.654, &#39;epoch&#39;: 0.81}
{&#39;loss&#39;: 0.0202, &#39;learning_rate&#39;: 8.061594202898551e-06, &#39;epoch&#39;: 0.86}
{&#39;loss&#39;: 0.0196, &#39;learning_rate&#39;: 5.797101449275362e-06, &#39;epoch&#39;: 0.9}
{&#39;loss&#39;: 0.0232, &#39;learning_rate&#39;: 3.5326086956521736e-06, &#39;epoch&#39;: 0.94}
{&#39;loss&#39;: 0.0183, &#39;learning_rate&#39;: 1.2681159420289857e-06, &#39;epoch&#39;: 0.98}
{&#39;eval_loss&#39;: 0.019303549081087112, &#39;eval_overall_precision&#39;: 0.7719162141194724, &#39;eval_overall_recall&#39;: 0.7673028725660305, &#39;eval_overall_f1&#39;: 0.769602629797931, &#39;eval_overall_accuracy&#39;: 0.9378442332014197, &#39;eval_runtime&#39;: 29.1715, &#39;eval_samples_per_second&#39;: 83.952, &#39;eval_steps_per_second&#39;: 21.014, &#39;epoch&#39;: 0.98}
{&#39;train_runtime&#39;: 450.609, &#39;train_samples_per_second&#39;: 21.788, &#39;train_steps_per_second&#39;: 2.723, &#39;train_loss&#39;: 0.056268237500824186, &#39;epoch&#39;: 1.0}
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TrainOutput(global_step=1227, training_loss=0.056268237500824186, metrics={&#39;train_runtime&#39;: 450.609, &#39;train_samples_per_second&#39;: 21.788, &#39;train_steps_per_second&#39;: 2.723, &#39;train_loss&#39;: 0.056268237500824186, &#39;epoch&#39;: 1.0})
</pre></div></div>
</div>
<p>And now the final step is to compute the model‚Äôs performance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
<span class="n">metrics</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;eval_loss&#39;: 0.019375888630747795,
 &#39;eval_art&#39;: {&#39;precision&#39;: 0.7661290322580645,
  &#39;recall&#39;: 0.7723577235772358,
  &#39;f1&#39;: 0.7692307692307692,
  &#39;number&#39;: 246},
 &#39;eval_building&#39;: {&#39;precision&#39;: 0.5842293906810035,
  &#39;recall&#39;: 0.6127819548872181,
  &#39;f1&#39;: 0.5981651376146789,
  &#39;number&#39;: 266},
 &#39;eval_event&#39;: {&#39;precision&#39;: 0.5497382198952879,
  &#39;recall&#39;: 0.5965909090909091,
  &#39;f1&#39;: 0.5722070844686648,
  &#39;number&#39;: 176},
 &#39;eval_location&#39;: {&#39;precision&#39;: 0.8036732108929703,
  &#39;recall&#39;: 0.8409542743538767,
  &#39;f1&#39;: 0.8218911917098446,
  &#39;number&#39;: 1509},
 &#39;eval_organization&#39;: {&#39;precision&#39;: 0.7474226804123711,
  &#39;recall&#39;: 0.6998069498069498,
  &#39;f1&#39;: 0.7228315054835494,
  &#39;number&#39;: 1036},
 &#39;eval_other&#39;: {&#39;precision&#39;: 0.6775818639798489,
  &#39;recall&#39;: 0.5604166666666667,
  &#39;f1&#39;: 0.61345496009122,
  &#39;number&#39;: 480},
 &#39;eval_person&#39;: {&#39;precision&#39;: 0.8636363636363636,
  &#39;recall&#39;: 0.9063313096270599,
  &#39;f1&#39;: 0.8844688954718578,
  &#39;number&#39;: 1153},
 &#39;eval_product&#39;: {&#39;precision&#39;: 0.7366666666666667,
  &#39;recall&#39;: 0.6884735202492211,
  &#39;f1&#39;: 0.7117552334943639,
  &#39;number&#39;: 321},
 &#39;eval_overall_precision&#39;: 0.7705836876691148,
 &#39;eval_overall_recall&#39;: 0.7686524002313476,
 &#39;eval_overall_f1&#39;: 0.7696168323520897,
 &#39;eval_overall_accuracy&#39;: 0.9381502182693484,
 &#39;eval_runtime&#39;: 28.5583,
 &#39;eval_samples_per_second&#39;: 85.754,
 &#39;eval_steps_per_second&#39;: 21.465,
 &#39;epoch&#39;: 1.0}
</pre></div></div>
</div>
<p>Additionally, we should evaluate using the test set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
This SpanMarker model won&#39;t be able to predict 0.285605% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words.
These are the frequencies of the missed entities due to maximum entity length out of 5252 total entities:
- 5 missed entities with 9 words (0.095202%)
- 1 missed entities with 10 words (0.019040%)
- 3 missed entities with 11 words (0.057121%)
- 2 missed entities with 12 words (0.038081%)
- 1 missed entities with 13 words (0.019040%)
- 1 missed entities with 17 words (0.019040%)
- 1 missed entities with 19 words (0.019040%)
- 1 missed entities with 40 words (0.019040%)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;test_loss&#39;: 0.01918497122824192,
 &#39;test_art&#39;: {&#39;precision&#39;: 0.7419354838709677,
  &#39;recall&#39;: 0.7488372093023256,
  &#39;f1&#39;: 0.7453703703703703,
  &#39;number&#39;: 215},
 &#39;test_building&#39;: {&#39;precision&#39;: 0.6236559139784946,
  &#39;recall&#39;: 0.710204081632653,
  &#39;f1&#39;: 0.6641221374045801,
  &#39;number&#39;: 245},
 &#39;test_event&#39;: {&#39;precision&#39;: 0.6153846153846154,
  &#39;recall&#39;: 0.5529953917050692,
  &#39;f1&#39;: 0.5825242718446603,
  &#39;number&#39;: 217},
 &#39;test_location&#39;: {&#39;precision&#39;: 0.812192118226601,
  &#39;recall&#39;: 0.8515171078114913,
  &#39;f1&#39;: 0.8313898518751971,
  &#39;number&#39;: 1549},
 &#39;test_organization&#39;: {&#39;precision&#39;: 0.7320754716981132,
  &#39;recall&#39;: 0.6897777777777778,
  &#39;f1&#39;: 0.7102974828375286,
  &#39;number&#39;: 1125},
 &#39;test_other&#39;: {&#39;precision&#39;: 0.7375886524822695,
  &#39;recall&#39;: 0.6328600405679513,
  &#39;f1&#39;: 0.6812227074235807,
  &#39;number&#39;: 493},
 &#39;test_person&#39;: {&#39;precision&#39;: 0.8805309734513275,
  &#39;recall&#39;: 0.9061930783242259,
  &#39;f1&#39;: 0.8931777378815081,
  &#39;number&#39;: 1098},
 &#39;test_product&#39;: {&#39;precision&#39;: 0.6641221374045801,
  &#39;recall&#39;: 0.5898305084745763,
  &#39;f1&#39;: 0.6247755834829445,
  &#39;number&#39;: 295},
 &#39;test_overall_precision&#39;: 0.7766859344894027,
 &#39;test_overall_recall&#39;: 0.7697154859652473,
 &#39;test_overall_f1&#39;: 0.7731850004795243,
 &#39;test_overall_accuracy&#39;: 0.938954021816699,
 &#39;test_runtime&#39;: 29.8808,
 &#39;test_samples_per_second&#39;: 81.658,
 &#39;test_steps_per_second&#39;: 20.414,
 &#39;epoch&#39;: 1.0}
</pre></div></div>
</div>
<p>Let‚Äôs try the model out with some predictions. For this we can use the <code class="docutils literal notranslate"><span class="pre">model.predict</span></code> method, which accepts either:</p>
<ul class="simple">
<li><p>A sentence as a string.</p></li>
<li><p>A tokenized sentence as a list of strings.</p></li>
<li><p>A list of sentences as a list of strings.</p></li>
<li><p>A list of tokenized sentences as a list of lists of strings.</p></li>
</ul>
<p>The method returns a list of dictionaries for each sentence, with the following keys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;label&quot;</span></code>: The string label for the found entity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;score&quot;</span></code>: The probability score indicating the model its confidence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;span&quot;</span></code>: The entity span as a string.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;word_start_index&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;word_end_index&quot;</span></code>: Integers useful for indexing the entity from a tokenized sentence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;char_start_index&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;char_end_index&quot;</span></code>: Integers useful for indexing the entity from a string sentence.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;The Ninth suffered a serious defeat at the Battle of Camulodunum under Quintus Petillius Cerialis in the rebellion of Boudica (61), when most of the foot-soldiers were killed in a disastrous attempt to relieve the besieged city of Camulodunum (Colchester).&quot;</span><span class="p">,</span>
    <span class="s2">&quot;He was born in Wellingborough, Northamptonshire, where he attended Victoria Junior School, Westfield Boys School and Sir Christopher Hatton School.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Nintendo continued to sell the revised Wii model and the Wii Mini alongside the Wii U during the Wii U&#39;s first release year.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Dorsa has a Bachelor of Music in Composition from California State University, Northridge in 2001, Master of Music in Harpsichord Performance at Cal State Northridge in 2004, and a Doctor of Musical Arts at the University of Michigan, Ann Arbor in 2008.&quot;</span>
<span class="p">]</span>

<span class="n">entities_per_sentence</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>

<span class="k">for</span> <span class="n">entities</span> <span class="ow">in</span> <span class="n">entities_per_sentence</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">entity</span><span class="p">[</span><span class="s2">&quot;span&quot;</span><span class="p">],</span> <span class="s2">&quot;=&gt;&quot;</span><span class="p">,</span> <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Battle of Camulodunum =&gt; event
Quintus Petillius Cerialis =&gt; person
Boudica =&gt; location
Camulodunum =&gt; location
Colchester =&gt; location

Wellingborough =&gt; location
Northamptonshire =&gt; location
Victoria Junior School =&gt; organization
Westfield Boys School =&gt; organization
Sir Christopher Hatton School =&gt; organization

Nintendo =&gt; organization
Wii =&gt; product
Wii Mini =&gt; product
Wii U =&gt; product
Wii U =&gt; product

Dorsa =&gt; person
Bachelor of Music in Composition =&gt; other
California State University =&gt; organization
Northridge =&gt; location
Master of Music in Harpsichord Performance =&gt; other
Cal State Northridge =&gt; organization
Doctor of Musical Arts =&gt; other
University of Michigan =&gt; organization
Ann Arbor =&gt; location
</pre></div></div>
</div>
<p>Very impressive performance for less than 8 minutes trained! üéâ</p>
<p>Once trained, we can save our new model locally. The saved model also comes with a flashy <code class="docutils literal notranslate"><span class="pre">README.md</span></code> such as <a class="reference external" href="https://huggingface.co/tomaarsen/span-marker-bert-base-uncased-bionlp">this one</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Or we can push it to the ü§ó Hub like so.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;span-marker-bert-base-fewnerd-coarse-super&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If we want to use it again, we can just load it using the checkpoint or using the model name on the Hub. This is how it would be done using a local checkpoint.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model = SpanMarkerModel.from_pretrained(&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;)</span>
</pre></div>
</div>
</div>
<p>That was all! As simple as that. If we put it all together into a single script, it looks something like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">SpanMarkerModel</span><span class="p">,</span> <span class="n">SpanMarkerModelCardData</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">dataset_id</span> <span class="o">=</span> <span class="s2">&quot;DFKI-SLT/few-nerd&quot;</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_id</span><span class="p">,</span> <span class="s2">&quot;supervised&quot;</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>

    <span class="n">encoder_id</span> <span class="o">=</span> <span class="s2">&quot;bert-base-cased&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="c1"># Required arguments</span>
        <span class="n">encoder_id</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="c1"># Optional arguments</span>
        <span class="n">model_max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">entity_max_length</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="c1"># To improve the generated model card</span>
        <span class="n">model_card_data</span><span class="o">=</span><span class="n">SpanMarkerModelCardData</span><span class="p">(</span>
            <span class="n">language</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;en&quot;</span><span class="p">],</span>
            <span class="n">license</span><span class="o">=</span><span class="s2">&quot;cc-by-sa-4.0&quot;</span><span class="p">,</span>
            <span class="n">encoder_id</span><span class="o">=</span><span class="n">encoder_id</span><span class="p">,</span>
            <span class="n">dataset_id</span><span class="o">=</span><span class="n">dataset_id</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super&quot;</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">dataloader_num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">8000</span><span class="p">)),</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span>
    <span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

    <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">wandb</span></code> initialized, you can enjoy their very useful training graphs straight in your browser. It ends up looking something like this. <img alt="image" src="https://user-images.githubusercontent.com/37621491/235196250-15d595f4-6d72-4625-bde9-f3783484997b.png" /> <img alt="image1" src="https://user-images.githubusercontent.com/37621491/235196335-6f36a7fb-5274-4ce5-a1f3-1d2ad35b26a4.png" /></p>
<p>Furthermore, you can use the <code class="docutils literal notranslate"><span class="pre">wandb</span></code> hyperparameter search functionality using the tutorial from the Hugging Face documentation <a class="reference external" href="https://huggingface.co/docs/transformers/hpo_train">here</a>. This transfers very well to the SpanMarker <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
</section>
</section>


        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../_sources/notebooks/getting_started.ipynb.txt" rel="nofollow"> source</a>
                    
                </li>
            

            

            
        </ul>

        
            <div id="copyright">
                &copy; 2024, Tom Aarsen
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>