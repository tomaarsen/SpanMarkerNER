<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>SpanMarker :: Getting Started with SpanMarker</title>
  
  <link rel="index" title="Index" href="../genindex.html"/>

  <link rel="stylesheet" href="../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../index.html">SpanMarker</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Notebooks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_training.html">Initializing &amp; Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_loading.html">Loading &amp; Inferencing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_configuration.html">Configurating</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/span_marker.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.modeling.html">span_marker.modeling module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.trainer.html">span_marker.trainer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.configuration.html">span_marker.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.data_collator.html">span_marker.data_collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.tokenizer.html">span_marker.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.evaluation.html">span_marker.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.label_normalizer.html">span_marker.label_normalizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/span_marker.output.html">span_marker.output module</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing SpanMarker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker on GitHub</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <div class="open-in-colab__wrapper">
<a href="https://colab.research.google.com/github/tomaarsen/SpanMarkerNER/blob/main/notebooks/getting_started.ipynb" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" style="display: inline; margin: 0" alt="Open In Colab"/>
</a>
</div><section id="Getting-Started-with-SpanMarker">
<h1>Getting Started with SpanMarker<a class="headerlink" href="#Getting-Started-with-SpanMarker" title="Permalink to this heading">¬∂</a></h1>
<p><a class="reference external" href="github.com/tomaarsen/SpanMarkerNER">SpanMarker</a> is an accessible yet powerful Python module for training Named Entity Recognition models.</p>
<p>In this notebook, we‚Äôll have a look at how to train an NER model using SpanMarker.</p>
<section id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this heading">¬∂</a></h2>
<p>First of all, the <code class="docutils literal notranslate"><span class="pre">span_marker</span></code> Python module needs to be installed. If we want to use <a class="reference external" href="https://wandb.ai/">Weights and Biases</a> for logging, we can install <code class="docutils literal notranslate"><span class="pre">span_marker</span></code> using the <code class="docutils literal notranslate"><span class="pre">[wandb]</span></code> extra.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install span_marker
<span class="c1"># %pip install span_marker[wandb]</span>
</pre></div>
</div>
</div>
</section>
<section id="Loading-the-dataset">
<h2>Loading the dataset<a class="headerlink" href="#Loading-the-dataset" title="Permalink to this heading">¬∂</a></h2>
<p>For this example, we‚Äôll load the challenging <a class="reference external" href="https://huggingface.co/datasets/DFKI-SLT/few-nerd">FewNERD supervised dataset</a> from the Hugging Face hub using ü§ó Datasets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;DFKI-SLT/few-nerd&quot;</span><span class="p">,</span> <span class="s2">&quot;supervised&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3359329/3359329 [00:09&lt;00:00, 342056.99it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 482037/482037 [00:01&lt;00:00, 346172.32it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 958765/958765 [00:02&lt;00:00, 346564.24it/s]
Dataset few-nerd downloaded and prepared to .... Subsequent calls will reuse this data.
DatasetDict({
    train: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 131767
    })
    validation: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 18824
    })
    test: Dataset({
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;ner_tags&#39;, &#39;fine_ner_tags&#39;],
        num_rows: 37648
    })
})
</pre></div></div>
</div>
<p>Let‚Äôs inspect some samples to get a feel for the data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;id&#39;: &#39;0&#39;, &#39;tokens&#39;: [&#39;Paul&#39;, &#39;International&#39;, &#39;airport&#39;, &#39;.&#39;], &#39;ner_tags&#39;: [0, 0, 0, 0], &#39;fine_ner_tags&#39;: [0, 0, 0, 0]}
{&#39;id&#39;: &#39;1&#39;, &#39;tokens&#39;: [&#39;It&#39;, &#39;starred&#39;, &#39;Hicks&#39;, &#34;&#39;s&#34;, &#39;wife&#39;, &#39;,&#39;, &#39;Ellaline&#39;, &#39;Terriss&#39;, &#39;and&#39;, &#39;Edmund&#39;, &#39;Payne&#39;, &#39;.&#39;], &#39;ner_tags&#39;: [0, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 0], &#39;fine_ner_tags&#39;: [0, 0, 51, 0, 0, 0, 50, 50, 0, 50, 50, 0]}
{&#39;id&#39;: &#39;2&#39;, &#39;tokens&#39;: [&#39;``&#39;, &#39;Time&#39;, &#39;``&#39;, &#39;magazine&#39;, &#39;said&#39;, &#39;the&#39;, &#39;film&#39;, &#39;was&#39;, &#39;``&#39;, &#39;a&#39;, &#39;multimillion&#39;, &#39;dollar&#39;, &#39;improvisation&#39;, &#39;that&#39;, &#39;does&#39;, &#39;everything&#39;, &#39;but&#39;, &#39;what&#39;, &#39;the&#39;, &#39;title&#39;, &#39;promises&#39;, &#34;&#39;&#39;&#34;, &#39;and&#39;, &#39;suggested&#39;, &#39;that&#39;, &#39;``&#39;, &#39;writer&#39;, &#39;George&#39;, &#39;Axelrod&#39;, &#39;(&#39;, &#39;``&#39;, &#39;The&#39;, &#39;Seven&#39;, &#39;Year&#39;, &#39;Itch&#39;, &#39;``&#39;, &#39;)&#39;, &#39;and&#39;, &#39;director&#39;, &#39;Richard&#39;, &#39;Quine&#39;, &#39;should&#39;, &#39;have&#39;, &#39;taken&#39;, &#39;a&#39;, &#39;hint&#39;, &#39;from&#39;, &#39;Holden&#39;, &#39;[&#39;, &#34;&#39;s&#34;, &#39;character&#39;, &#39;Richard&#39;, &#39;Benson&#39;, &#39;]&#39;, &#39;,&#39;, &#39;who&#39;, &#39;writes&#39;, &#39;his&#39;, &#39;movie&#39;, &#39;,&#39;, &#39;takes&#39;, &#39;a&#39;, &#39;long&#39;, &#39;sober&#39;, &#39;look&#39;, &#39;at&#39;, &#39;what&#39;, &#39;he&#39;, &#39;has&#39;, &#39;wrought&#39;, &#39;,&#39;, &#39;and&#39;, &#39;burns&#39;, &#39;it&#39;, &#39;.&#39;, &#34;&#39;&#39;&#34;], &#39;ner_tags&#39;: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;fine_ner_tags&#39;: [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 51, 0, 0, 6, 6, 6, 6, 0, 0, 0, 0, 53, 53, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
</pre></div></div>
</div>
<p>As you can see, this dataset contains <code class="docutils literal notranslate"><span class="pre">tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> and a <code class="docutils literal notranslate"><span class="pre">fine_ner_tags</span></code> columns. Let‚Äôs have a look at which labels these last two represent using the <a class="reference external" href="https://huggingface.co/docs/datasets/about_dataset_features">Dataset features</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;O&#39;, &#39;art&#39;, &#39;building&#39;, &#39;event&#39;, &#39;location&#39;, &#39;organization&#39;, &#39;other&#39;, &#39;person&#39;, &#39;product&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fine_labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;fine_ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fine_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;O&#39;, &#39;art-broadcastprogram&#39;, &#39;art-film&#39;, &#39;art-music&#39;, &#39;art-other&#39;, &#39;art-painting&#39;, &#39;art-writtenart&#39;, &#39;building-airport&#39;, &#39;building-hospital&#39;, &#39;building-hotel&#39;, &#39;building-library&#39;, &#39;building-other&#39;, &#39;building-restaurant&#39;, &#39;building-sportsfacility&#39;, &#39;building-theater&#39;, &#39;event-attack/battle/war/militaryconflict&#39;, &#39;event-disaster&#39;, &#39;event-election&#39;, &#39;event-other&#39;, &#39;event-protest&#39;, &#39;event-sportsevent&#39;, &#39;location-GPE&#39;, &#39;location-bodiesofwater&#39;, &#39;location-island&#39;, &#39;location-mountain&#39;, &#39;location-other&#39;, &#39;location-park&#39;, &#39;location-road/railway/highway/transit&#39;, &#39;organization-company&#39;, &#39;organization-education&#39;, &#39;organization-government/governmentagency&#39;, &#39;organization-media/newspaper&#39;, &#39;organization-other&#39;, &#39;organization-politicalparty&#39;, &#39;organization-religion&#39;, &#39;organization-showorganization&#39;, &#39;organization-sportsleague&#39;, &#39;organization-sportsteam&#39;, &#39;other-astronomything&#39;, &#39;other-award&#39;, &#39;other-biologything&#39;, &#39;other-chemicalthing&#39;, &#39;other-currency&#39;, &#39;other-disease&#39;, &#39;other-educationaldegree&#39;, &#39;other-god&#39;, &#39;other-language&#39;, &#39;other-law&#39;, &#39;other-livingthing&#39;, &#39;other-medical&#39;, &#39;person-actor&#39;, &#39;person-artist/author&#39;, &#39;person-athlete&#39;, &#39;person-director&#39;, &#39;person-other&#39;, &#39;person-politician&#39;, &#39;person-scholar&#39;, &#39;person-soldier&#39;, &#39;product-airplane&#39;, &#39;product-car&#39;, &#39;product-food&#39;, &#39;product-game&#39;, &#39;product-other&#39;, &#39;product-ship&#39;, &#39;product-software&#39;, &#39;product-train&#39;, &#39;product-weapon&#39;]
</pre></div></div>
</div>
<p>For the purposes of this tutorial, let‚Äôs stick with the <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> coarse-grained labels, but I challenge you to modify this Notebook to train for the fine labels. For the SpanMarker model, any dataset can be used as long as it has a <code class="docutils literal notranslate"><span class="pre">tokens</span></code> and a <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> column. The <code class="docutils literal notranslate"><span class="pre">ner_tags</span></code> can be annotated using the IOB, IOB2, BIOES or BILOU labeling scheme, but also regular unschemed labels like in this FewNERD example can be used.</p>
</section>
<section id="Initializing-a-SpanMarkerModel">
<h2>Initializing a <code class="docutils literal notranslate"><span class="pre">SpanMarkerModel</span></code><a class="headerlink" href="#Initializing-a-SpanMarkerModel" title="Permalink to this heading">¬∂</a></h2>
<p>A SpanMarker model is initialized via <a class="reference external" href="https://tomaarsen.github.io/SpanMarkerNER/api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.from_pretrained">SpanMarkerModel.from_pretrained</a>. This method will be familiar to those who know ü§ó Transformers. It accepts either a path to a local model or the name of a model on the <a class="reference external" href="https://huggingface.co/models">Hugging Face Hub</a>.</p>
<p>Importantly, the model can <em>either</em> be an encoder or an already trained and saved SpanMarker model. As we haven‚Äôt trained anything yet, we will use an encoder. To learn how to load and use a saved SpanMarker model, please have a look at the <a class="reference internal" href="model_loading.html"><span class="doc">Loading &amp; Inferencing</span></a> notebook.</p>
<p>Reasonable options for encoders include BERT, RoBERTa, etc., which means that the following are all good options: <code class="docutils literal notranslate"><span class="pre">&quot;bert-base-cased&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;bert-large-cased&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;roberta-base&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;roberta-large&quot;</span></code>. Not all encoders work though, they <strong>must</strong> allow for <code class="docutils literal notranslate"><span class="pre">position_ids</span></code> as an input argument, which disqualifies DistilBERT, T5, DistilRoBERTa, ALBERT &amp; BART. Furthermore, using uncased models is generally not recommended, as the capitalisation can be very useful to find named entities.</p>
<p>We‚Äôll use <code class="docutils literal notranslate"><span class="pre">&quot;bert-base-cased&quot;</span></code> for this notebook. If you‚Äôre running this on Google Colab, be sure to set hardware accelerator to ‚ÄúGPU‚Äù in <code class="docutils literal notranslate"><span class="pre">Runtime</span></code> &gt; <code class="docutils literal notranslate"><span class="pre">Change</span> <span class="pre">runtime</span> <span class="pre">type</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">SpanMarkerModel</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;bert-base-cased&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">model_max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;]
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</pre></div></div>
</div>
<p>For us, these warnings are expected, as we are initializing <code class="docutils literal notranslate"><span class="pre">BertModel</span></code> for a new task.</p>
<p>Note that we provided <code class="docutils literal notranslate"><span class="pre">SpanMarkerModel.from_pretrained</span></code> with a list of our labels. This is required when training a new model using an encoder. Furthermore, we can specify some useful configuration parameters from <code class="docutils literal notranslate"><span class="pre">SpanMarkerConfig</span></code>, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_max_length</span></code>: The maximum number of tokens that the model will process. If you only use short sentences for your model, reducing this number may help training and inference speeds with no loss in performance. Defaults to the encoder maximum, or 512 if the encoder doesn‚Äôt have a maximum.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entity_max_length</span></code>: The total number of words that one entity can be. Defaults to 16.</p></li>
</ul>
</section>
<section id="Training">
<h2>Training<a class="headerlink" href="#Training" title="Permalink to this heading">¬∂</a></h2>
<p>At this point, our model is already ready for training! We can import <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> directly from ü§ó Transformers as well as the SpanMarker <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> is a subclass of the ü§ó Transformers <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer">Trainer</a> that simplifies some tasks for you, but otherwise it works just like the regular <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<p>This next snippet shows some reasonable defaults. Feel free to adjust the batch size to a lower value if you experience out of memory exceptions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">dataloader_num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we can create a SpanMarker <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> in the same way that you would initialize a ü§ó Transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. We‚Äôll train on a subsection of the data to save us some time. Amazingly, this <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> will automatically create logs using exactly the logging tools that you have installed. With other words, if you prefer logging with <a class="reference external" href="https://www.tensorflow.org/tensorboard">Tensorboard</a>, all that you have to do is install it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">8000</span><span class="p">)),</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let‚Äôs start training!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
This SpanMarker model will ignore 0.339050% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words.
These are the frequencies of the missed entities due to maximum entity length out of 20351 total entities:
- 24 missed entities with 9 words (0.117930%)
- 15 missed entities with 10 words (0.073706%)
- 14 missed entities with 11 words (0.068793%)
- 7 missed entities with 12 words (0.034396%)
- 5 missed entities with 13 words (0.024569%)
- 2 missed entities with 15 words (0.009828%)
- 1 missed entities with 17 words (0.004914%)
- 1 missed entities with 19 words (0.004914%)
Tracking run with wandb version 0.14.0
Run data is saved locally in ...
Syncing run colorful-leaf-761 to Weights &amp; Biases
{&#39;loss&#39;: 0.9012, &#39;learning_rate&#39;: 2.032520325203252e-05, &#39;epoch&#39;: 0.04}
{&#39;loss&#39;: 0.0813, &#39;learning_rate&#39;: 4.065040650406504e-05, &#39;epoch&#39;: 0.08}
{&#39;loss&#39;: 0.0514, &#39;learning_rate&#39;: 4.8777173913043476e-05, &#39;epoch&#39;: 0.12}
{&#39;loss&#39;: 0.0385, &#39;learning_rate&#39;: 4.651268115942029e-05, &#39;epoch&#39;: 0.16}
This SpanMarker model won&#39;t be able to predict 0.307515% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words.
These are the frequencies of the missed entities due to maximum entity length out of 5203 total entities:
- 5 missed entities with 9 words (0.096098%)
- 5 missed entities with 10 words (0.096098%)
- 2 missed entities with 11 words (0.038439%)
- 1 missed entities with 12 words (0.019220%)
- 3 missed entities with 13 words (0.057659%)
{&#39;eval_loss&#39;: 0.03596973791718483, &#39;eval_overall_precision&#39;: 0.6802749427202666, &#39;eval_overall_recall&#39;: 0.6297724643270344, &#39;eval_overall_f1&#39;: 0.6540502653449485, &#39;eval_overall_accuracy&#39;: 0.9053643208390295, &#39;eval_runtime&#39;: 28.0718, &#39;eval_samples_per_second&#39;: 87.241, &#39;eval_steps_per_second&#39;: 21.837, &#39;epoch&#39;: 0.16}
{&#39;loss&#39;: 0.0334, &#39;learning_rate&#39;: 4.42481884057971e-05, &#39;epoch&#39;: 0.2}
{&#39;loss&#39;: 0.0306, &#39;learning_rate&#39;: 4.1983695652173914e-05, &#39;epoch&#39;: 0.24}
{&#39;loss&#39;: 0.0278, &#39;learning_rate&#39;: 3.971920289855073e-05, &#39;epoch&#39;: 0.29}
Loading cached processed dataset at ...
Loading cached processed dataset at ...
{&#39;loss&#39;: 0.0245, &#39;learning_rate&#39;: 3.745471014492754e-05, &#39;epoch&#39;: 0.33}
{&#39;eval_loss&#39;: 0.023754317313432693, &#39;eval_overall_precision&#39;: 0.7612159329140461, &#39;eval_overall_recall&#39;: 0.700154261473197, &#39;eval_overall_f1&#39;: 0.7294094013660104, &#39;eval_overall_accuracy&#39;: 0.9214634046807729, &#39;eval_runtime&#39;: 28.2374, &#39;eval_samples_per_second&#39;: 86.729, &#39;eval_steps_per_second&#39;: 21.709, &#39;epoch&#39;: 0.33}
{&#39;loss&#39;: 0.0257, &#39;learning_rate&#39;: 3.5190217391304346e-05, &#39;epoch&#39;: 0.37}
{&#39;loss&#39;: 0.0237, &#39;learning_rate&#39;: 3.292572463768116e-05, &#39;epoch&#39;: 0.41}
{&#39;loss&#39;: 0.0234, &#39;learning_rate&#39;: 3.066123188405797e-05, &#39;epoch&#39;: 0.45}
{&#39;loss&#39;: 0.0241, &#39;learning_rate&#39;: 2.8396739130434785e-05, &#39;epoch&#39;: 0.49}
{&#39;eval_loss&#39;: 0.02093053236603737, &#39;eval_overall_precision&#39;: 0.7934713036057179, &#39;eval_overall_recall&#39;: 0.7171230235248747, &#39;eval_overall_f1&#39;: 0.7533677706877343, &#39;eval_overall_accuracy&#39;: 0.9292782958232162, &#39;eval_runtime&#39;: 28.1912, &#39;eval_samples_per_second&#39;: 86.871, &#39;eval_steps_per_second&#39;: 21.744, &#39;epoch&#39;: 0.49}
{&#39;loss&#39;: 0.021, &#39;learning_rate&#39;: 2.6132246376811598e-05, &#39;epoch&#39;: 0.53}
{&#39;loss&#39;: 0.02, &#39;learning_rate&#39;: 2.3867753623188408e-05, &#39;epoch&#39;: 0.57}
{&#39;loss&#39;: 0.022, &#39;learning_rate&#39;: 2.1603260869565217e-05, &#39;epoch&#39;: 0.61}
Loading cached processed dataset at ...
Loading cached processed dataset at ...
{&#39;loss&#39;: 0.0237, &#39;learning_rate&#39;: 1.933876811594203e-05, &#39;epoch&#39;: 0.65}
{&#39;eval_loss&#39;: 0.020754070952534676, &#39;eval_overall_precision&#39;: 0.7628806742003448, &#39;eval_overall_recall&#39;: 0.7680293096799075, &#39;eval_overall_f1&#39;: 0.7654463341981359, &#39;eval_overall_accuracy&#39;: 0.9358077087881818, &#39;eval_runtime&#39;: 28.0953, &#39;eval_samples_per_second&#39;: 87.168, &#39;eval_steps_per_second&#39;: 21.819, &#39;epoch&#39;: 0.65}
{&#39;loss&#39;: 0.0226, &#39;learning_rate&#39;: 1.7074275362318843e-05, &#39;epoch&#39;: 0.69}
{&#39;loss&#39;: 0.0218, &#39;learning_rate&#39;: 1.4809782608695653e-05, &#39;epoch&#39;: 0.73}
{&#39;loss&#39;: 0.0242, &#39;learning_rate&#39;: 1.2545289855072464e-05, &#39;epoch&#39;: 0.77}
Loading cached processed dataset at ...
Loading cached processed dataset at ...
{&#39;loss&#39;: 0.0197, &#39;learning_rate&#39;: 1.0280797101449275e-05, &#39;epoch&#39;: 0.81}
{&#39;eval_loss&#39;: 0.019617434591054916, &#39;eval_overall_precision&#39;: 0.7771473292897672, &#39;eval_overall_recall&#39;: 0.7659082144234477, &#39;eval_overall_f1&#39;: 0.7714868408274256, &#39;eval_overall_accuracy&#39;: 0.937746128262156, &#39;eval_runtime&#39;: 28.2921, &#39;eval_samples_per_second&#39;: 86.561, &#39;eval_steps_per_second&#39;: 21.667, &#39;epoch&#39;: 0.81}
{&#39;loss&#39;: 0.0191, &#39;learning_rate&#39;: 8.016304347826086e-06, &#39;epoch&#39;: 0.86}
{&#39;loss&#39;: 0.0187, &#39;learning_rate&#39;: 5.751811594202898e-06, &#39;epoch&#39;: 0.9}
{&#39;loss&#39;: 0.0202, &#39;learning_rate&#39;: 3.4873188405797104e-06, &#39;epoch&#39;: 0.94}
Loading cached processed dataset at ...
Loading cached processed dataset at ...
{&#39;loss&#39;: 0.0221, &#39;learning_rate&#39;: 1.2228260869565218e-06, &#39;epoch&#39;: 0.98}
{&#39;eval_loss&#39;: 0.019159900024533272, &#39;eval_overall_precision&#39;: 0.7773279352226721, &#39;eval_overall_recall&#39;: 0.7774778249132279, &#39;eval_overall_f1&#39;: 0.7774028728429576, &#39;eval_overall_accuracy&#39;: 0.9399702095533473, &#39;eval_runtime&#39;: 28.0225, &#39;eval_samples_per_second&#39;: 87.394, &#39;eval_steps_per_second&#39;: 21.875, &#39;epoch&#39;: 0.98}
{&#39;train_runtime&#39;: 453.1296, &#39;train_samples_per_second&#39;: 21.667, &#39;train_steps_per_second&#39;: 2.708, &#39;train_loss&#39;: 0.06319850289734186, &#39;epoch&#39;: 1.0}
TrainOutput(global_step=1227, training_loss=0.06319850289734186, metrics={&#39;train_runtime&#39;: 453.1296, &#39;train_samples_per_second&#39;: 21.667, &#39;train_steps_per_second&#39;: 2.708, &#39;train_loss&#39;: 0.06319850289734186, &#39;epoch&#39;: 1.0})
</pre></div></div>
</div>
<p>And now the final step is to compute the model‚Äôs performance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
<span class="n">metrics</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading cached processed dataset at ...
Loading cached processed dataset at ...
{&#39;eval_loss&#39;: 0.019206691533327103,
 &#39;eval_overall_precision&#39;: 0.7758985200845666,
 &#39;eval_overall_recall&#39;: 0.7784419591207096,
 &#39;eval_overall_f1&#39;: 0.7771681586293194,
 &#39;eval_overall_accuracy&#39;: 0.9398477830602543,
 &#39;eval_runtime&#39;: 28.0849,
 &#39;eval_samples_per_second&#39;: 87.2,
 &#39;eval_steps_per_second&#39;: 21.827,
 &#39;epoch&#39;: 1.0}
</pre></div></div>
</div>
<p>Additionally, we should evaluate using the test set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
This SpanMarker model won&#39;t be able to predict 0.285605% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words.
These are the frequencies of the missed entities due to maximum entity length out of 5252 total entities:
- 5 missed entities with 9 words (0.095202%)
- 1 missed entities with 10 words (0.019040%)
- 3 missed entities with 11 words (0.057121%)
- 2 missed entities with 12 words (0.038081%)
- 1 missed entities with 13 words (0.019040%)
- 1 missed entities with 17 words (0.019040%)
- 1 missed entities with 19 words (0.019040%)
- 1 missed entities with 40 words (0.019040%)
{&#39;test_loss&#39;: 0.019189156591892242,
 &#39;test_overall_precision&#39;: 0.769879287219774,
 &#39;test_overall_recall&#39;: 0.7679663608562691,
 &#39;test_overall_f1&#39;: 0.7689216342933691,
 &#39;test_overall_accuracy&#39;: 0.938544749464231,
 &#39;test_runtime&#39;: 28.0932,
 &#39;test_samples_per_second&#39;: 86.854,
 &#39;test_steps_per_second&#39;: 21.713,
 &#39;epoch&#39;: 1.0}
</pre></div></div>
</div>
<p>Let‚Äôs try the model out with some predictions. For this we can use the <code class="docutils literal notranslate"><span class="pre">model.predict</span></code> method, which accepts either:</p>
<ul class="simple">
<li><p>A sentence as a string.</p></li>
<li><p>A tokenized sentence as a list of strings.</p></li>
<li><p>A list of sentences as a list of strings.</p></li>
<li><p>A list of tokenized sentences as a list of lists of strings.</p></li>
</ul>
<p>The method returns a list of dictionaries for each sentence, with the following keys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;label&quot;</span></code>: The string label for the found entity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;score&quot;</span></code>: The probability score indicating the model its confidence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;span&quot;</span></code>: The entity span as a string.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;word_start_index&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;word_end_index&quot;</span></code>: Integers useful for indexing the entity from a tokenized sentence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;char_start_index&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;char_end_index&quot;</span></code>: Integers useful for indexing the entity from a string sentence.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;The Ninth suffered a serious defeat at the Battle of Camulodunum under Quintus Petillius Cerialis in the rebellion of Boudica (61), when most of the foot-soldiers were killed in a disastrous attempt to relieve the besieged city of Camulodunum (Colchester).&quot;</span><span class="p">,</span>
    <span class="s2">&quot;He was born in Wellingborough, Northamptonshire, where he attended Victoria Junior School, Westfield Boys School and Sir Christopher Hatton School.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Nintendo continued to sell the revised Wii model and the Wii Mini alongside the Wii U during the Wii U&#39;s first release year.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Dorsa has a Bachelor of Music in Composition from California State University, Northridge in 2001, Master of Music in Harpsichord Performance at Cal State Northridge in 2004, and a Doctor of Musical Arts at the University of Michigan, Ann Arbor in 2008.&quot;</span>
<span class="p">]</span>

<span class="n">entities_per_sentence</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>

<span class="k">for</span> <span class="n">entities</span> <span class="ow">in</span> <span class="n">entities_per_sentence</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">entity</span><span class="p">[</span><span class="s2">&quot;span&quot;</span><span class="p">],</span> <span class="s2">&quot;=&gt;&quot;</span><span class="p">,</span> <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Battle of Camulodunum =&gt; event
Quintus Petillius Cerialis =&gt; person
Boudica =&gt; person

Wellingborough =&gt; location
Northamptonshire =&gt; location
Victoria Junior School =&gt; organization
Westfield Boys School =&gt; organization
Sir Christopher Hatton School =&gt; organization

Nintendo =&gt; organization
Wii =&gt; product
Wii Mini =&gt; product
Wii U =&gt; product
Wii U =&gt; product

Dorsa =&gt; person
Bachelor of Music in Composition =&gt; other
California State University =&gt; organization
Northridge =&gt; location
Cal State Northridge =&gt; organization
Ann Arbor =&gt; organization

</pre></div></div>
</div>
<p>Very impressive performance for less than 8 minutes trained! üéâ</p>
<p>Once trained, we can save our new model locally.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Or we can push it to the ü§ó Hub like so. I‚Äôve commented it away for now to prevent people from accidentally pushing models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># trainer.push_to_hub()</span>
</pre></div>
</div>
</div>
<p>If we want to use it again, we can just load it using the checkpoint or using the model name on the Hub. This is how it would be done using a local checkpoint.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model = SpanMarkerModel.from_pretrained(&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;)</span>
</pre></div>
</div>
</div>
<p>That was all! As simple as that. If we put it all together into a single script, it looks something like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">SpanMarkerModel</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;DFKI-SLT/few-nerd&quot;</span><span class="p">,</span> <span class="s2">&quot;supervised&quot;</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>

    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;bert-base-cased&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super&quot;</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">dataloader_num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">8000</span><span class="p">)),</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">)),</span>
    <span class="p">)</span>

    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;models/span-marker-bert-base-fewnerd-coarse-super/checkpoint-final&quot;</span><span class="p">)</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">wandb</span></code> initialized, you can enjoy their very useful training graphs straight in your browser. It ends up looking something like this. <img alt="image" src="https://user-images.githubusercontent.com/37621491/235196250-15d595f4-6d72-4625-bde9-f3783484997b.png" /> <img alt="image1" src="https://user-images.githubusercontent.com/37621491/235196335-6f36a7fb-5274-4ce5-a1f3-1d2ad35b26a4.png" /></p>
<p>Furthermore, you can use the <code class="docutils literal notranslate"><span class="pre">wandb</span></code> hyperparameter search functionality using the tutorial from the Hugging Face documentation <a class="reference external" href="https://huggingface.co/docs/transformers/hpo_train">here</a>. This transfers very well to the SpanMarker <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
</section>
</section>


        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../_sources/notebooks/getting_started.ipynb.txt" rel="nofollow"> source</a>
                    
                </li>
            

            

            
        </ul>

        
            <div id="copyright">
                &copy; 2023, Tom Aarsen
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>