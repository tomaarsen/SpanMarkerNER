<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>SpanMarker :: span_marker.trainer</title>
  
  <link rel="index" title="Index" href="../../genindex.html"/>

  <link rel="stylesheet" href="../../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../../index.html">SpanMarker</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/index.html">Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/getting_started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_training.html">Initializing &amp; Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_loading.html">Loading &amp; Inferencing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_configuration.html">Configuring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/spacy_integration.html">SpanMarker with spaCy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/document_level_context.html">Document-level context</a></li>
<li class="toctree-l2"><a class="reference external" href="https://raw.githubusercontent.com/tomaarsen/SpanMarkerNER/main/thesis.pdf">SpanMarker Thesis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/span_marker.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.modeling.html">span_marker.modeling module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.trainer.html">span_marker.trainer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.configuration.html">span_marker.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.model_card.html">span_marker.model_card module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.pipeline_component.html">span_marker.pipeline_component module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.data_collator.html">span_marker.data_collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.tokenizer.html">span_marker.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.evaluation.html">span_marker.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.label_normalizer.html">span_marker.label_normalizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.output.html">span_marker.output module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.spacy_integration.html">span_marker.spacy_integration module</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installing SpanMarker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../news.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker on GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://huggingface.co/models?library=span-marker">SpanMarker on the ðŸ¤— Hub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://spacy.io/universe/project/span_marker">SpanMarker on spaCy</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for span_marker.trainer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">tqdm.autonotebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EvalPrediction</span><span class="p">,</span>
    <span class="n">TrainerCallback</span><span class="p">,</span>
    <span class="n">TrainingArguments</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span> <span class="k">as</span> <span class="n">TransformersTrainer</span>
<span class="kn">from</span> <span class="nn">transformers.trainer_utils</span> <span class="kn">import</span> <span class="n">PredictionOutput</span>

<span class="kn">from</span> <span class="nn">span_marker.evaluation</span> <span class="kn">import</span> <span class="n">compute_f1_via_seqeval</span>
<span class="kn">from</span> <span class="nn">span_marker.label_normalizer</span> <span class="kn">import</span> <span class="n">AutoLabelNormalizer</span><span class="p">,</span> <span class="n">LabelNormalizer</span>
<span class="kn">from</span> <span class="nn">span_marker.model_card</span> <span class="kn">import</span> <span class="n">ModelCardCallback</span>
<span class="kn">from</span> <span class="nn">span_marker.modeling</span> <span class="kn">import</span> <span class="n">SpanMarkerModel</span>
<span class="kn">from</span> <span class="nn">span_marker.tokenizer</span> <span class="kn">import</span> <span class="n">SpanMarkerTokenizer</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="Trainer"><a class="viewcode-back" href="../../api/span_marker.trainer.html#span_marker.trainer.Trainer">[docs]</a><span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span><span class="n">TransformersTrainer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trainer is a simple but feature-complete training and eval loop for SpanMarker,</span>
<span class="sd">    built tightly on top of the ðŸ¤— Transformers :external:doc:`Trainer &lt;main_classes/trainer&gt;`.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (Optional[SpanMarkerModel]):</span>
<span class="sd">            The model to train, evaluate or use for predictions. If not provided, a ``model_init`` must be passed.</span>
<span class="sd">        args (Optional[~transformers.TrainingArguments]):</span>
<span class="sd">            The arguments to tweak for training. Will default to a basic instance of :class:`~transformers.TrainingArguments` with the</span>
<span class="sd">            ``output_dir`` set to a directory named *models/my_span_marker_model* in the current directory if not provided.</span>
<span class="sd">        train_dataset (Optional[~datasets.Dataset]):</span>
<span class="sd">            The dataset to use for training. Must contain ``tokens`` and ``ner_tags`` columns, and may contain</span>
<span class="sd">            ``document_id`` and ``sentence_id`` columns for document-level context during training.</span>
<span class="sd">        eval_dataset (Optional[~datasets.Dataset]):</span>
<span class="sd">            The dataset to use for evaluation. Must contain ``tokens`` and ``ner_tags`` columns, and may contain</span>
<span class="sd">            ``document_id`` and ``sentence_id`` columns for document-level context during evaluation.</span>
<span class="sd">        model_init (Optional[Callable[[], SpanMarkerModel]]):</span>
<span class="sd">            A function that instantiates the model to be used. If provided, each call to :meth:`Trainer.train` will start</span>
<span class="sd">            from a new instance of the model as given by this function.</span>

<span class="sd">            The function may have zero argument, or a single one containing the optuna/Ray Tune/SigOpt trial object, to</span>
<span class="sd">            be able to choose different architectures according to hyper parameters (such as layer count, sizes of</span>
<span class="sd">            inner layers, dropout probabilities etc).</span>
<span class="sd">        compute_metrics (Optional[Callable[[~transformers.EvalPrediction], Dict]]):</span>
<span class="sd">            The function that will be used to compute metrics at evaluation. Must take a :class:`~transformers.EvalPrediction` and return</span>
<span class="sd">            a dictionary string to metric values.</span>
<span class="sd">        callbacks (Optional[List[~transformers.TrainerCallback]]):</span>
<span class="sd">            A list of callbacks to customize the training loop. Will add those to the list of default callbacks</span>
<span class="sd">            detailed in the Hugging Face :external:doc:`Callback documentation &lt;main_classes/callback&gt;`.</span>

<span class="sd">            If you want to remove one of the default callbacks used, use the :meth:`~Trainer.remove_callback` method.</span>
<span class="sd">        optimizers (Tuple[Optional[~torch.optim.Optimizer], Optional[~torch.optim.lr_scheduler.LambdaLR]]): A tuple</span>
<span class="sd">            containing the optimizer and the scheduler to use. Will default to an instance of ``AdamW`` on your model</span>
<span class="sd">            and a scheduler given by ``get_linear_schedule_with_warmup`` controlled by ``args``.</span>
<span class="sd">        preprocess_logits_for_metrics (Optional[Callable[[~torch.Tensor, ~torch.Tensor], ~torch.Tensor]]):</span>
<span class="sd">            A function that preprocess the logits right before caching them at each evaluation step. Must take two</span>
<span class="sd">            tensors, the logits and the labels, and return the logits once processed as desired. The modifications made</span>
<span class="sd">            by this function will be reflected in the predictions received by ``compute_metrics``.</span>

<span class="sd">            Note that the labels (second parameter) will be ``None`` if the dataset does not have them.</span>

<span class="sd">    Important attributes:</span>

<span class="sd">        - **model** -- Always points to the core model.</span>
<span class="sd">        - **model_wrapped** -- Always points to the most external model in case one or more other modules wrap the</span>
<span class="sd">          original model. This is the model that should be used for the forward pass. For example, under ``DeepSpeed``,</span>
<span class="sd">          the inner model is wrapped in ``DeepSpeed`` and then again in :class:`torch.nn.DistributedDataParallel`. If the</span>
<span class="sd">          inner model hasn&#39;t been wrapped, then ``self.model_wrapped`` is the same as ``self.model``.</span>
<span class="sd">        - **is_model_parallel** -- Whether or not a model has been switched to a model parallel mode (different from</span>
<span class="sd">          data parallelism, this means some of the model layers are split on different GPUs).</span>
<span class="sd">        - **place_model_on_device** -- Whether or not to automatically place the model on the device - it will be set</span>
<span class="sd">          to ``False`` if model parallel or deepspeed is used, or if the default</span>
<span class="sd">          `TrainingArguments.place_model_on_device` is overridden to return ``False``.</span>
<span class="sd">        - **is_in_train** -- Whether or not a model is currently running :meth:`~Trainer.train` (e.g. when ``evaluate`` is called while</span>
<span class="sd">          in ``train``)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">REQUIRED_COLUMNS</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;ner_tags&quot;</span><span class="p">)</span>
    <span class="n">OPTIONAL_COLUMNS</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SpanMarkerModel</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainingArguments</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_init</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">SpanMarkerModel</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compute_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">EvalPrediction</span><span class="p">],</span> <span class="n">Dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TrainerCallback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizers</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">preprocess_logits_for_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Extract the model from an initializer function</span>
        <span class="k">if</span> <span class="n">model_init</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_init</span> <span class="o">=</span> <span class="n">model_init</span>
            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_model_init</span><span class="p">()</span>

        <span class="c1"># To convert dataset labels to a common format (list of label-start-end tuples)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_normalizer</span> <span class="o">=</span> <span class="n">AutoLabelNormalizer</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Set some Training arguments that must be set for SpanMarker</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;models/my_span_marker_model&quot;</span><span class="p">,</span> <span class="n">include_inputs_for_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">include_inputs_for_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Always compute `compute_f1_via_seqeval` - optionally compute user-provided metrics</span>
        <span class="k">if</span> <span class="n">compute_metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">compute_metrics_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">eval_prediction</span><span class="p">:</span> <span class="p">{</span>
                <span class="o">**</span><span class="n">compute_f1_via_seqeval</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">eval_prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_in_train</span><span class="p">),</span>
                <span class="o">**</span><span class="n">compute_metrics</span><span class="p">(</span><span class="n">eval_prediction</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">compute_metrics_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">eval_prediction</span><span class="p">:</span> <span class="n">compute_f1_via_seqeval</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">eval_prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_in_train</span>
            <span class="p">)</span>

        <span class="c1"># If the model ID is set via the TrainingArguments, but not via the SpanMarkerModelCardData,</span>
        <span class="c1"># then we can set it here for the model card regardless</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">hub_model_id</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">model_id</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">model_id</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">hub_model_id</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">dataset_id</span><span class="p">:</span>
            <span class="c1"># Inferring is hacky - it may break in the future, so let&#39;s be safe</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">infer_dataset_id</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
            <span class="n">data_collator</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">model_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics_func</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">,</span>
            <span class="n">preprocess_logits_for_metrics</span><span class="o">=</span><span class="n">preprocess_logits_for_metrics</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># We have to provide the __init__ with None for model_init and then override it here again</span>
        <span class="c1"># We do this because we need `model` to already be defined in this SpanMarker Trainer class</span>
        <span class="c1"># and the Transformers Trainer would complain if we provide both a model and a model_init</span>
        <span class="c1"># in its __init__.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_init</span> <span class="o">=</span> <span class="n">model_init</span>

        <span class="c1"># Override the type hint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">SpanMarkerModel</span>

        <span class="c1"># Add the callback for filling the model card data with hyperparameters</span>
        <span class="c1"># and evaluation results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="n">ModelCardCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>

<div class="viewcode-block" id="Trainer.preprocess_dataset"><a class="viewcode-back" href="../../api/span_marker.trainer.html#span_marker.trainer.Trainer.preprocess_dataset">[docs]</a>    <span class="k">def</span> <span class="nf">preprocess_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span>
        <span class="n">label_normalizer</span><span class="p">:</span> <span class="n">LabelNormalizer</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">SpanMarkerTokenizer</span><span class="p">,</span>
        <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
        <span class="n">is_evaluate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize the ``ner_tags`` labels and call tokenizer on ``tokens``.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (~datasets.Dataset): A Hugging Face dataset with ``tokens`` and ``ner_tags`` columns.</span>
<span class="sd">            label_normalizer (LabelNormalizer): A callable that normalizes ``ner_tags`` into start-end-label tuples.</span>
<span class="sd">            tokenizer (SpanMarkerTokenizer): The tokenizer responsible for tokenizing ``tokens`` into input IDs,</span>
<span class="sd">                and adding start and end markers.</span>
<span class="sd">            dataset_name (str, optional): The name of the dataset. Defaults to &quot;train&quot;.</span>
<span class="sd">            is_evaluate (bool, optional): Whether to return the number of words for each sample.</span>
<span class="sd">                Required for evaluation. Defaults to False.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the ``dataset`` does not contain ``tokens`` and ``ner_tags`` columns.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset: The normalized and tokenized version of the input dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">REQUIRED_COLUMNS</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> dataset must contain a </span><span class="si">{</span><span class="n">column</span><span class="si">!r}</span><span class="s2"> column.&quot;</span><span class="p">)</span>

        <span class="c1"># Drop all unused columns, only keep &quot;tokens&quot;, &quot;ner_tags&quot;, &quot;document_id&quot;, &quot;sentence_id&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">OPTIONAL_COLUMNS</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">REQUIRED_COLUMNS</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Normalize the labels to a common format (list of label-start-end tuples)</span>
        <span class="c1"># Also add &quot;entity_count&quot; and &quot;word_count&quot; labels</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">label_normalizer</span><span class="p">,</span>
            <span class="n">input_columns</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;ner_tags&quot;</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Label normalizing the </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> dataset&quot;</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Setting model card data based on training data</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_evaluate</span><span class="p">:</span>
            <span class="c1"># Pick some example entities from each entity class for the model card.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">label_example_list</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">set_label_examples</span><span class="p">(</span>
                    <span class="n">dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">outside_id</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">train_set_metrics_list</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">set_train_set_metrics</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># Set some example sentences for the model card widget</span>
        <span class="k">if</span> <span class="n">is_evaluate</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">widget</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_card_data</span><span class="o">.</span><span class="n">set_widget_examples</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># Remove dataset columns that are only used for model card</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">((</span><span class="s2">&quot;entity_count&quot;</span><span class="p">,</span> <span class="s2">&quot;word_count&quot;</span><span class="p">))</span>

        <span class="c1"># Tokenize and add start/end markers</span>
        <span class="k">with</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">entity_tracker</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">):</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">OPTIONAL_COLUMNS</span><span class="p">),</span>
                <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Tokenizing the </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> dataset&quot;</span><span class="p">,</span>
                <span class="n">fn_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;return_num_words&quot;</span><span class="p">:</span> <span class="n">is_evaluate</span><span class="p">},</span>
            <span class="p">)</span>
        <span class="c1"># If &quot;document_id&quot; AND &quot;sentence_id&quot; exist in the training dataset</span>
        <span class="k">if</span> <span class="p">{</span><span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">}</span> <span class="o">&lt;=</span> <span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
            <span class="c1"># If training, set the config flag that this model is trained with document context</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_evaluate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trained_with_document_context</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># If evaluating and the model was not trained with document context, warn</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trained_with_document_context</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;This model was trained without document-level context: &quot;</span>
                    <span class="s2">&quot;evaluation with document-level context may cause decreased performance.&quot;</span>
                <span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">])</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_context</span><span class="p">(</span>
                <span class="n">dataset</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">max_prev_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_prev_context</span><span class="p">,</span>
                <span class="n">max_next_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_next_context</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_evaluate</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trained_with_document_context</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;This model was trained with document-level context: &quot;</span>
                <span class="s2">&quot;evaluation without document-level context may cause decreased performance.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Spread between multiple samples where needed</span>
        <span class="n">original_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">Trainer</span><span class="o">.</span><span class="n">spread_sample</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Spreading data between multiple samples&quot;</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model_max_length&quot;</span><span class="p">:</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="s2">&quot;marker_max_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">marker_max_length</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">)</span>
        <span class="n">new_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Spread </span><span class="si">{</span><span class="n">original_length</span><span class="si">}</span><span class="s2"> sentences across </span><span class="si">{</span><span class="n">new_length</span><span class="si">}</span><span class="s2"> samples, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;a </span><span class="si">{</span><span class="p">(</span><span class="n">new_length</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">original_length</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">%</span><span class="si">}</span><span class="s2"> increase. You can increase &quot;</span>
            <span class="s2">&quot;`model_max_length` or `marker_max_length` to decrease the number of samples, &quot;</span>
            <span class="s2">&quot;but recognize that longer samples are slower.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>

<div class="viewcode-block" id="Trainer.add_context"><a class="viewcode-back" href="../../api/span_marker.trainer.html#span_marker.trainer.Trainer.add_context">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">add_context</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span>
        <span class="n">model_max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">max_prev_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_next_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add document-level context from previous and next sentences in the same document.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (`Dataset`): The partially processed dataset, containing `&quot;input_ids&quot;`, `&quot;start_position_ids&quot;`,</span>
<span class="sd">                `&quot;end_position_ids&quot;`, `&quot;document_id&quot;` and `&quot;sentence_id&quot;` columns.</span>
<span class="sd">            model_max_length (`int`): The total number of tokens that can be processed before</span>
<span class="sd">                truncation.</span>
<span class="sd">            max_prev_context (`Optional[int]`): The maximum number of previous sentences to include. Defaults to None,</span>
<span class="sd">                representing as many previous sentences as fits.</span>
<span class="sd">            max_next_context (`Optional[int]`): The maximum number of next sentences to include. Defaults to None,</span>
<span class="sd">                representing as many previous sentences as fits.</span>
<span class="sd">            show_progress_bar (`bool`): Whether to show a progress bar. Defaults to `True`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset: A copy of the Dataset with additional previous and next sentences added to input_ids.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">all_input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_start_position_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_end_position_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sample_idx</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Adding document-level context&quot;</span><span class="p">,</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span>
            <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">show_progress_bar</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Sequentially add next context, previous context, next context, previous context, etc. until</span>
            <span class="c1"># max token length or max_prev/next_context</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">start_position_ids</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">]</span>
            <span class="n">end_position_ids</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;end_position_ids&quot;</span><span class="p">]</span>

            <span class="n">next_context_added</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">prev_context_added</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">remaining_space</span> <span class="o">=</span> <span class="n">model_max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="k">while</span> <span class="n">remaining_space</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">next_context_index</span> <span class="o">=</span> <span class="n">sample_idx</span> <span class="o">+</span> <span class="n">next_context_added</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">should_add_next</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">max_next_context</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">next_context_added</span> <span class="o">&lt;</span> <span class="n">max_next_context</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">next_context_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">dataset</span><span class="p">[</span><span class="n">next_context_index</span><span class="p">][</span><span class="s2">&quot;document_id&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;document_id&quot;</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">should_add_next</span><span class="p">:</span>
                    <span class="c1"># TODO: [1:-1][:remaining_space] is not efficient</span>
                    <span class="n">tokens</span> <span class="o">+=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">next_context_index</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">remaining_space</span><span class="p">]</span>
                    <span class="n">next_context_added</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">remaining_space</span> <span class="o">=</span> <span class="n">model_max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">remaining_space</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">break</span>

                <span class="n">prev_context_index</span> <span class="o">=</span> <span class="n">sample_idx</span> <span class="o">-</span> <span class="n">prev_context_added</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">should_add_prev</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">max_prev_context</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">prev_context_added</span> <span class="o">&lt;</span> <span class="n">max_prev_context</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">prev_context_index</span> <span class="o">&gt;=</span> <span class="mi">0</span>
                    <span class="ow">and</span> <span class="n">dataset</span><span class="p">[</span><span class="n">prev_context_index</span><span class="p">][</span><span class="s2">&quot;document_id&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;document_id&quot;</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">should_add_prev</span><span class="p">:</span>
                    <span class="c1"># TODO: [1:-1][remaining_space:] is not efficient</span>
                    <span class="n">prepended_tokens</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">prev_context_index</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="n">remaining_space</span><span class="p">:]</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="n">prepended_tokens</span> <span class="o">+</span> <span class="n">tokens</span>
                    <span class="c1"># TODO: Use numpy? np.array(sample[&quot;start_position_ids&quot;]) + len(prepended_tokens)</span>
                    <span class="n">start_position_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">prepended_tokens</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">start_position_ids</span><span class="p">]</span>
                    <span class="n">end_position_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">prepended_tokens</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">end_position_ids</span><span class="p">]</span>
                    <span class="n">prev_context_added</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">should_add_next</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">should_add_prev</span><span class="p">:</span>
                    <span class="k">break</span>

                <span class="n">remaining_space</span> <span class="o">=</span> <span class="n">model_max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>

            <span class="n">all_input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="n">tokens</span> <span class="o">+</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
            <span class="n">all_start_position_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">start_position_ids</span><span class="p">)</span>
            <span class="n">all_end_position_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end_position_ids</span><span class="p">)</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">((</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;start_position_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;end_position_ids&quot;</span><span class="p">))</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="n">all_input_ids</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">,</span> <span class="n">all_start_position_ids</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;end_position_ids&quot;</span><span class="p">,</span> <span class="n">all_end_position_ids</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dataset</span></div>

<div class="viewcode-block" id="Trainer.spread_sample"><a class="viewcode-back" href="../../api/span_marker.trainer.html#span_marker.trainer.Trainer.spread_sample">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">spread_sample</span><span class="p">(</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]],</span> <span class="n">model_max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">marker_max_length</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Spread sentences between multiple samples if lack of space per sample requires it.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (`Dict[str, List[Any]]`): A dictionary of dataset keys to lists of values.</span>
<span class="sd">            model_max_length (`int`): The total number of tokens that can be processed before</span>
<span class="sd">                truncation.</span>
<span class="sd">            marker_max_length (`int`): The maximum length for each of the span markers. A value of 128</span>
<span class="sd">                means that each training and inferencing sample contains a maximum of 128 start markers</span>
<span class="sd">                and 128 end markers, for a total of 256 markers per sample.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, List[Any]]: A dictionary of dataset keys to lists of values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="n">total_sample_length</span> <span class="o">=</span> <span class="n">model_max_length</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">marker_max_length</span>

        <span class="n">batch_samples</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">):</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">sample</span><span class="p">))</span>
            <span class="n">sample_marker_space</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_sample_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]))</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">spread_between_n</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">sample_marker_space</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spread_between_n</span><span class="p">):</span>
                <span class="n">sample_copy</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">sample_marker_space</span>
                <span class="n">end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">sample_marker_space</span>
                <span class="n">sample_copy</span><span class="p">[</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">][</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                <span class="n">sample_copy</span><span class="p">[</span><span class="s2">&quot;end_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;end_position_ids&quot;</span><span class="p">][</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
                    <span class="n">sample_copy</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                <span class="n">sample_copy</span><span class="p">[</span><span class="s2">&quot;num_spans&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_copy</span><span class="p">[</span><span class="s2">&quot;start_position_ids&quot;</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sample_copy</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">batch_samples</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch_samples</span></div>

    <span class="k">def</span> <span class="nf">get_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the preprocessed training DataLoader.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_normalizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_eval_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the preprocessed evaluation DataLoader.&quot;&quot;&quot;</span>
        <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span>
        <span class="k">if</span> <span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_dataset</span><span class="p">(</span>
                <span class="n">eval_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_normalizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;evaluation&quot;</span><span class="p">,</span> <span class="n">is_evaluate</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_eval_dataloader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the preprocessed evaluation DataLoader.&quot;&quot;&quot;</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_dataset</span><span class="p">(</span>
            <span class="n">test_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_normalizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">is_evaluate</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_test_dataloader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;test&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PredictionOutput</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`Trainer.predict` is not recommended for a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Consider using `</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.predict` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="p">)</span>

<div class="viewcode-block" id="Trainer.create_model_card"><a class="viewcode-back" href="../../api/span_marker.trainer.html#span_marker.trainer.Trainer.create_model_card">[docs]</a>    <span class="k">def</span> <span class="nf">create_model_card</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">_args</span><span class="p">,</span> <span class="o">**</span><span class="n">_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a draft of a model card using the information available to the `Trainer`,</span>
<span class="sd">        the `SpanMarkerModel` and the `SpanMarkerModelCardData`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;README.md&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate_model_card</span><span class="p">())</span></div></div>
</pre></div>

        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            

            
        </ul>

        
            <div id="copyright">
                &copy; 2024, Tom Aarsen
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>