<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>SpanMarker :: span_marker.modeling</title>
  
  <link rel="index" title="Index" href="../../genindex.html"/>

  <link rel="stylesheet" href="../../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../../index.html">SpanMarker</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/index.html">Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/getting_started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_training.html">Initializing &amp; Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_loading.html">Loading &amp; Inferencing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/model_configuration.html">Configuring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/spacy_integration.html">SpanMarker with spaCy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/document_level_context.html">Document-level context</a></li>
<li class="toctree-l2"><a class="reference external" href="https://raw.githubusercontent.com/tomaarsen/SpanMarkerNER/main/thesis.pdf">SpanMarker Thesis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/span_marker.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.modeling.html">span_marker.modeling module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.trainer.html">span_marker.trainer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.configuration.html">span_marker.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.data_collator.html">span_marker.data_collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.tokenizer.html">span_marker.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.evaluation.html">span_marker.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.label_normalizer.html">span_marker.label_normalizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.output.html">span_marker.output module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/span_marker.spacy_integration.html">span_marker.spacy_integration module</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installing SpanMarker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../news.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker on GitHub</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for span_marker.modeling</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">disable_progress_bar</span><span class="p">,</span> <span class="n">enable_progress_bar</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">Version</span><span class="p">,</span> <span class="n">parse</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">device</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">tqdm.autonotebook</span> <span class="kn">import</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">PretrainedConfig</span><span class="p">,</span> <span class="n">PreTrainedModel</span>
<span class="kn">from</span> <span class="nn">typing_extensions</span> <span class="kn">import</span> <span class="n">Self</span>

<span class="kn">from</span> <span class="nn">span_marker</span> <span class="kn">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">span_marker_version</span>
<span class="kn">from</span> <span class="nn">span_marker.configuration</span> <span class="kn">import</span> <span class="n">SpanMarkerConfig</span>
<span class="kn">from</span> <span class="nn">span_marker.data_collator</span> <span class="kn">import</span> <span class="n">SpanMarkerDataCollator</span>
<span class="kn">from</span> <span class="nn">span_marker.model_card</span> <span class="kn">import</span> <span class="n">generate_model_card</span>
<span class="kn">from</span> <span class="nn">span_marker.output</span> <span class="kn">import</span> <span class="n">SpanMarkerOutput</span>
<span class="kn">from</span> <span class="nn">span_marker.tokenizer</span> <span class="kn">import</span> <span class="n">SpanMarkerTokenizer</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">&quot;SpanMarkerModel&quot;</span><span class="p">)</span>

<span class="n">UNEXPECTED_KEYWORD_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;\S+ got an unexpected keyword argument &#39;([^&#39;]*)&#39;&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="SpanMarkerModel"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel">[docs]</a><span class="k">class</span> <span class="nc">SpanMarkerModel</span><span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This SpanMarker model allows for Named Entity Recognition (NER) using a variety of underlying encoders,</span>
<span class="sd">    such as BERT and RoBERTa. The model should be initialized using :meth:`~SpanMarkerModel.from_pretrained`,</span>
<span class="sd">    e.g. like so:</span>

<span class="sd">    &gt;&gt;&gt; # Initialize a SpanMarkerModel using a pretrained encoder</span>
<span class="sd">    &gt;&gt;&gt; model = SpanMarkerModel.from_pretrained(&quot;bert-base-cased&quot;, labels=[&quot;O&quot;, &quot;B-PER&quot;, &quot;I-PER&quot;, &quot;B-ORG&quot;, &quot;I-ORG&quot;, ...])</span>
<span class="sd">    &gt;&gt;&gt; # Load a pretrained SpanMarker model</span>
<span class="sd">    &gt;&gt;&gt; model = SpanMarkerModel.from_pretrained(&quot;tomaarsen/span-marker-bert-base-fewnerd-fine-super&quot;)</span>

<span class="sd">    After the model is loaded (and finetuned if it wasn&#39;t already), it can be used to predict entities:</span>

<span class="sd">    &gt;&gt;&gt; model.predict(&quot;A prototype was fitted in the mid-&#39;60s in a one-off DB5 extended 4&#39;&#39; after the doors and &quot;</span>
<span class="sd">    ... &quot;driven by Marek personally, and a normally 6-cylinder Aston Martin DB7 was equipped with a V8 unit in 1998.&quot;)</span>
<span class="sd">    [{&#39;span&#39;: &#39;DB5&#39;, &#39;label&#39;: &#39;product-car&#39;, &#39;score&#39;: 0.8675689101219177, &#39;char_start_index&#39;: 52, &#39;char_end_index&#39;: 55},</span>
<span class="sd">     {&#39;span&#39;: &#39;Marek&#39;, &#39;label&#39;: &#39;person-other&#39;, &#39;score&#39;: 0.9100819230079651, &#39;char_start_index&#39;: 99, &#39;char_end_index&#39;: 104},</span>
<span class="sd">     {&#39;span&#39;: &#39;Aston Martin DB7&#39;, &#39;label&#39;: &#39;product-car&#39;, &#39;score&#39;: 0.9931442737579346, &#39;char_start_index&#39;: 143, &#39;char_end_index&#39;: 159}]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">config_class</span> <span class="o">=</span> <span class="n">SpanMarkerConfig</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;encoder&quot;</span>
    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># To support `load_in_8bit=True`` and `device_map=&quot;auto&quot;`</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SpanMarkerConfig</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PreTrainedModel</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize a SpanMarkerModel using configuration.</span>

<span class="sd">        Do not manually initialize a SpanMarkerModel this way! Use :meth:`~SpanMarkerModel.from_pretrained` instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            config (SpanMarkerConfig): The configuration for this model.</span>
<span class="sd">            encoder (Optional[PreTrainedModel]): A PreTrainedModel acting as the underlying encoder.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="c1"># `encoder` will be specified if this Model is initializer via .from_pretrained with an encoder</span>
        <span class="c1"># If .from_pretrained is called with a SpanMarkerModel instance, then we use the &quot;traditional&quot;</span>
        <span class="c1"># PreTrainedModel.from_pretrained, which won&#39;t include an encoder keyword argument. In that case,</span>
        <span class="c1"># we must create an &quot;empty&quot; encoder for PreTrainedModel.from_pretrained to fill with the correct</span>
        <span class="c1"># weights.</span>
        <span class="k">if</span> <span class="n">encoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Load the encoder via the Config to prevent having to use AutoModel.from_pretrained, which</span>
            <span class="c1"># could load e.g. all of `roberta-large` from the Hub unnecessarily.</span>
            <span class="c1"># However, use the SpanMarkerModel updated vocab_size</span>
            <span class="n">encoder_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;_name_or_path&quot;</span><span class="p">],</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">encoder_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>

        <span class="n">dropout_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="s2">&quot;hidden_dropout_prob&quot;</span><span class="p">,</span> <span class="s2">&quot;dropout_rate&quot;</span><span class="p">],</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout_rate</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="c1"># TODO: Get a less arbitrary default</span>
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="c1"># tokenizer and data collator are filled using set_tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">SpanMarkerTokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span> <span class="o">=</span> <span class="n">SpanMarkerDataCollator</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">marker_max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">marker_max_length</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the weights&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
            <span class="n">initializer_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;initializer_range&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<div class="viewcode-block" id="SpanMarkerModel.forward"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">start_marker_indices</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">num_marker_pairs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_words</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">document_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sentence_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpanMarkerOutput</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward call of the SpanMarkerModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_ids (~torch.Tensor): Input IDs including start/end markers.</span>
<span class="sd">            attention_mask (~torch.Tensor): Attention mask matrix including one-directional attention for markers.</span>
<span class="sd">            position_ids (~torch.Tensor): Position IDs including start/end markers.</span>
<span class="sd">            start_marker_indices (~torch.Tensor): The indices where the start markers begin per batch sample.</span>
<span class="sd">            num_marker_pairs (~torch.Tensor): The number of start/end marker pairs per batch sample.</span>
<span class="sd">            labels (Optional[~torch.Tensor]): The labels for each span candidate. Defaults to None.</span>
<span class="sd">            num_words (Optional[~torch.Tensor]): The number of words for each batch sample. Defaults to None.</span>
<span class="sd">            document_ids (Optional[~torch.Tensor]): The document ID of each batch sample. Defaults to None.</span>
<span class="sd">            sentence_ids (Optional[~torch.Tensor]): The index of each sentence in their respective document. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpanMarkerOutput: The output dataclass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Get the indices where the end markers start</span>
        <span class="n">end_marker_indices</span> <span class="o">=</span> <span class="n">start_marker_indices</span> <span class="o">+</span> <span class="n">num_marker_pairs</span>

        <span class="c1"># The start marker embeddings concatenated with the end marker embeddings.</span>
        <span class="c1"># This is kind of breaking the cardinal rule of GPU-based ML, as this is processing</span>
        <span class="c1"># the batch iteratively per sample, but every sample produces a different shape matrix</span>
        <span class="c1"># and this is the most convenient way to recombine them into a matrix.</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">last_hidden_state</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">start_marker_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">end_marker_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
                        <span class="n">last_hidden_state</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">end_marker_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">end_marker_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">num_marker_pairs</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
                    <span class="p">),</span>
                    <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">padded_embeddings</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sequence_length</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">for</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="n">embeddings</span>
        <span class="p">]</span>
        <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">padded_embeddings</span><span class="p">)</span>

        <span class="c1"># NOTE: This was wrong in the older tests</span>
        <span class="n">feature_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">feature_vector</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">feature_vector</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">SpanMarkerOutput</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="o">*</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span>
            <span class="n">num_marker_pairs</span><span class="o">=</span><span class="n">num_marker_pairs</span><span class="p">,</span>
            <span class="n">num_words</span><span class="o">=</span><span class="n">num_words</span><span class="p">,</span>
            <span class="n">document_ids</span><span class="o">=</span><span class="n">document_ids</span><span class="p">,</span>
            <span class="n">sentence_ids</span><span class="o">=</span><span class="n">sentence_ids</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SpanMarkerModel.from_pretrained"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.from_pretrained">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
        <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span>
        <span class="o">*</span><span class="n">model_args</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a pretrained pytorch model from a pre-trained model configuration.</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; # Initialize a SpanMarkerModel using a pretrained encoder</span>
<span class="sd">            &gt;&gt;&gt; model = SpanMarkerModel.from_pretrained(&quot;bert-base-cased&quot;, labels=[&quot;O&quot;, &quot;B-PER&quot;, &quot;I-PER&quot;, &quot;B-ORG&quot;, &quot;I-ORG&quot;, ...])</span>
<span class="sd">            &gt;&gt;&gt; # Load a pretrained SpanMarker model</span>
<span class="sd">            &gt;&gt;&gt; model = SpanMarkerModel.from_pretrained(&quot;tomaarsen/span-marker-bert-base-fewnerd-fine-super&quot;)</span>

<span class="sd">        Args:</span>
<span class="sd">            pretrained_model_name_or_path (Union[str, os.PathLike]):</span>
<span class="sd">                Either a pretrained encoder (e.g. ``bert-base-cased``, ``roberta-large``, etc.), or a pretrained SpanMarkerModel.</span>
<span class="sd">                Can be either:</span>

<span class="sd">                    - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.</span>
<span class="sd">                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under a</span>
<span class="sd">                      user or organization name, like ``dbmdz/bert-base-german-cased``.</span>
<span class="sd">                    - A path to a *directory* containing model weights saved using</span>
<span class="sd">                      :meth:`SpanMarkerModel.save_pretrained`, e.g., ``./my_model_directory/``.</span>
<span class="sd">                    - A path or url to a *tensorflow index checkpoint file* (e.g, ``./tf_model/model.ckpt.index``). In</span>
<span class="sd">                      this case, ``from_tf`` should be set to ``True`` and a configuration object should be provided as</span>
<span class="sd">                      ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a</span>
<span class="sd">                      PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</span>
<span class="sd">                    - A path or url to a model folder containing a *flax checkpoint file* in *.msgpack* format (e.g,</span>
<span class="sd">                      ``./flax_model/`` containing ``flax_model.msgpack``). In this case, ``from_flax`` should be set to</span>
<span class="sd">                      ``True``.</span>

<span class="sd">            labels (List[str], optional): A list of string labels corresponding to the ``ner_tags`` in your datasets.</span>
<span class="sd">                Only necessary when loading a SpanMarker model using a pretrained encoder. Defaults to None.</span>

<span class="sd">        Additional arguments are passed to :class:`~span_marker.configuration.SpanMarkerConfig` and the ``from_pretrained`` methods of</span>
<span class="sd">        :class:`~transformers.AutoConfig`, :class:`~transformers.AutoModel` and :class:`~span_marker.tokenizer.SpanMarkerTokenizer`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpanMarkerModel: A :class:`SpanMarkerModel` instance, either ready for training using the :class:`Trainer` or\</span>
<span class="sd">                for inference via :meth:`SpanMarkerModel.predict`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If loading a SpanMarkerConfig, then we don&#39;t want to override id2label and label2id</span>
        <span class="c1"># Create an encoder or SpanMarker config</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># if &#39;pretrained_model_name_or_path&#39; refers to a SpanMarkerModel instance, initialize it directly</span>
        <span class="n">loading_span_marker</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">config_class</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">loading_span_marker</span><span class="p">:</span>
            <span class="n">model_span_marker_version</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;span_marker_version&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;0.1.0&quot;</span>
            <span class="k">if</span> <span class="n">parse</span><span class="p">(</span><span class="n">model_span_marker_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0.0.dev&quot;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Loading a model trained using SpanMarker v</span><span class="si">{</span><span class="n">model_span_marker_version</span><span class="si">}</span><span class="s2">,&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; while SpanMarker v</span><span class="si">{</span><span class="n">span_marker_version</span><span class="si">}</span><span class="s2"> is installed. Due to large changes&quot;</span>
                    <span class="s2">&quot; introduced in v1.0.0, this is not recommended. Either retrain your model for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; v</span><span class="si">{</span><span class="n">span_marker_version</span><span class="si">}</span><span class="s2">, or install `span_marker &lt; 1.0.0`.&quot;</span>
                <span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># If &#39;pretrained_model_name_or_path&#39; refers to an encoder (roberta, bert, distilbert, electra, etc.),</span>
        <span class="c1"># then initialize it and create the SpanMarker config and model using the encoder and its config.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">_load_encoder_with_kwargs</span><span class="p">(</span>
                <span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Please provide a `labels` list to `SpanMarkerModel.from_pretrained()`, e.g.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;&gt;&gt;&gt; SpanMarkerModel.from_pretrained(</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s1">&#39;...     &quot;</span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s1">&quot;,</span><span class="se">\n</span><span class="s1">&#39;</span>
                    <span class="s1">&#39;...     labels=[&quot;O&quot;, &quot;B-PER&quot;, &quot;I-PER&quot;, &quot;B-ORG&quot;, &quot;I-ORG&quot;, ...]</span><span class="se">\n</span><span class="s1">&#39;</span>
                    <span class="s2">&quot;... )</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;or</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;&gt;&gt;&gt; SpanMarkerModel.from_pretrained(</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s1">&#39;...     &quot;</span><span class="si">{</span><span class="n">pretrained_model_name_or_path</span><span class="si">}</span><span class="s1">&quot;,</span><span class="se">\n</span><span class="s1">&#39;</span>
                    <span class="s1">&#39;...     labels=[&quot;O&quot;, &quot;PER&quot;, &quot;ORG&quot;, &quot;LOC&quot;, &quot;MISC&quot;]</span><span class="se">\n</span><span class="s1">&#39;</span>
                    <span class="s2">&quot;... )&quot;</span>
                <span class="p">)</span>
            <span class="n">config</span><span class="o">.</span><span class="n">id2label</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="n">config</span><span class="o">.</span><span class="n">label2id</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="c1"># Set the span_marker version for freshly initialized models</span>
            <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">config_class</span><span class="p">(</span>
                <span class="n">encoder_config</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">span_marker_version</span><span class="o">=</span><span class="n">span_marker_version</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Pass the tokenizer directly to the model for convenience, this way the user doesn&#39;t have to</span>
        <span class="c1"># make it themselves.</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SpanMarkerTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_name_or_path&quot;</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">),</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">set_tokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">model</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_load_encoder_with_kwargs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PreTrainedModel</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load an underlying encoder using keyword arguments, even if those kwargs are not (all) supported.</span>

<span class="sd">        Args:</span>
<span class="sd">            pretrained_model_name_or_path (str): The model name or path, e.g. ``bert-base-cased``.</span>
<span class="sd">            config (PretrainedConfig): The config corresponding with the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PreTrainedModel: The loaded encoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">pretrained_model_name_or_path</span><span class="p">,</span>
                <span class="o">*</span><span class="n">model_args</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
            <span class="c1"># If we can find a specific keyword that is causing issues, remove it and try again</span>
            <span class="n">match</span> <span class="o">=</span> <span class="n">UNEXPECTED_KEYWORD_PATTERN</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exc</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
                <span class="n">problematic_keyword</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">problematic_keyword</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">problematic_keyword</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">_load_encoder_with_kwargs</span><span class="p">(</span>
                        <span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">model_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
            <span class="c1"># Otherwise, just raise the exception</span>
            <span class="k">raise</span> <span class="n">exc</span>

<div class="viewcode-block" id="SpanMarkerModel.predict"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">Dataset</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict named entities from input texts.</span>

<span class="sd">        Example::</span>

<span class="sd">            &gt;&gt;&gt; model = SpanMarkerModel.from_pretrained(...)</span>
<span class="sd">            &gt;&gt;&gt; model.predict(&quot;Amelia Earhart flew her single engine Lockheed Vega 5B across the Atlantic to Paris.&quot;)</span>
<span class="sd">            [{&#39;span&#39;: &#39;Amelia Earhart&#39;, &#39;label&#39;: &#39;person-other&#39;, &#39;score&#39;: 0.7629689574241638, &#39;char_start_index&#39;: 0, &#39;char_end_index&#39;: 14},</span>
<span class="sd">             {&#39;span&#39;: &#39;Lockheed Vega 5B&#39;, &#39;label&#39;: &#39;product-airplane&#39;, &#39;score&#39;: 0.9833564758300781, &#39;char_start_index&#39;: 38, &#39;char_end_index&#39;: 54},</span>
<span class="sd">             {&#39;span&#39;: &#39;Atlantic&#39;, &#39;label&#39;: &#39;location-bodiesofwater&#39;, &#39;score&#39;: 0.7621214389801025, &#39;char_start_index&#39;: 66, &#39;char_end_index&#39;: 74},</span>
<span class="sd">             {&#39;span&#39;: &#39;Paris&#39;, &#39;label&#39;: &#39;location-GPE&#39;, &#39;score&#39;: 0.9807717204093933, &#39;char_start_index&#39;: 78, &#39;char_end_index&#39;: 83}]</span>
<span class="sd">            &gt;&gt;&gt; model.predict([&#39;Caesar&#39;, &#39;led&#39;, &#39;the&#39;, &#39;Roman&#39;, &#39;armies&#39;, &#39;in&#39;, &#39;the&#39;, &#39;Gallic&#39;, &#39;Wars&#39;, &#39;before&#39;, &#39;defeating&#39;, &#39;his&#39;, &#39;political&#39;, &#39;rival&#39;, &#39;Pompey&#39;, &#39;in&#39;, &#39;a&#39;, &#39;civil&#39;, &#39;war&#39;])</span>
<span class="sd">            [{&#39;span&#39;: [&#39;Caesar&#39;], &#39;label&#39;: &#39;person-politician&#39;, &#39;score&#39;: 0.683479905128479, &#39;word_start_index&#39;: 0, &#39;word_end_index&#39;: 1},</span>
<span class="sd">             {&#39;span&#39;: [&#39;Roman&#39;], &#39;label&#39;: &#39;location-GPE&#39;, &#39;score&#39;: 0.7114525437355042, &#39;word_start_index&#39;: 3, &#39;word_end_index&#39;: 4},</span>
<span class="sd">             {&#39;span&#39;: [&#39;Gallic&#39;, &#39;Wars&#39;], &#39;label&#39;: &#39;event-attack/battle/war/militaryconflict&#39;, &#39;score&#39;: 0.9015670418739319, &#39;word_start_index&#39;: 7, &#39;word_end_index&#39;: 9},</span>
<span class="sd">             {&#39;span&#39;: [&#39;Pompey&#39;], &#39;label&#39;: &#39;person-politician&#39;, &#39;score&#39;: 0.9601260423660278, &#39;word_start_index&#39;: 14, &#39;word_end_index&#39;: 15}]</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (Union[str, List[str], List[List[str]], Dataset]): Input sentences from which to extract entities.</span>
<span class="sd">                Valid datastructures are:</span>

<span class="sd">                * str: a string sentence.</span>
<span class="sd">                * List[str]: a pre-tokenized string sentence, i.e. a list of words.</span>
<span class="sd">                * List[str]: a list of multiple string sentences.</span>
<span class="sd">                * List[List[str]]: a list of multiple pre-tokenized string sentences, i.e. a list with lists of words.</span>
<span class="sd">                * Dataset: A  :class:`~datasets.Dataset` with a ``tokens`` column and optionally ``document_id`` and ``sentence_id`` columns.</span>
<span class="sd">                    If the optional columns are provided, they will be used to provide document-level context.</span>

<span class="sd">            batch_size (int): The number of samples to include in a batch, a higher batch size is faster,</span>
<span class="sd">                but requires more memory. Defaults to 4</span>
<span class="sd">            show_progress_bar (bool): Whether to show a progress bar, useful for longer inputs. Defaults to `False`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[List[Dict[str, Union[str, int, float]]], List[List[Dict[str, Union[str, int, float]]]]]:</span>
<span class="sd">                If the input is a single sentence, then we output a list of dictionaries. Each dictionary</span>
<span class="sd">                represents one predicted entity, and contains the following keys:</span>

<span class="sd">                * ``label``: The predicted entity label.</span>
<span class="sd">                * ``span``: The text that the model deems an entity.</span>
<span class="sd">                * ``score``: The model its confidence.</span>
<span class="sd">                * ``word_start_index`` &amp; ``word_end_index``: The word indices for the start/end of the entity,</span>
<span class="sd">                  if the input is pre-tokenized.</span>
<span class="sd">                * ``char_start_index`` &amp; ``char_end_index``: The character indices for the start/end of the entity,</span>
<span class="sd">                  if the input is a string.</span>

<span class="sd">                If the input is multiple sentences, then we return a list containing multiple of the aforementioned lists.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">span_marker.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;SpanMarker model predictions are being computed on the CPU while CUDA is available.&quot;</span>
                <span class="s2">&quot; Moving the model to CUDA using `model.cuda()` before performing predictions is heavily&quot;</span>
                <span class="s2">&quot; recommended to significantly boost prediction speeds.&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Disable dropout, etc.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Track whether the input was a string sentence or a list of tokens</span>
        <span class="n">single_input</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># Check if inputs is a string, i.e. a string sentence, or</span>
        <span class="c1"># if it is a list of strings without spaces, i.e. if it&#39;s 1 tokenized sentence</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot; &quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">single_input</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">&quot;tokens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]})</span>

        <span class="c1"># Otherwise, we likely have a list of strings, i.e. a list of string sentences,</span>
        <span class="c1"># or a list of lists of strings, i.e. a list of tokenized sentences</span>
        <span class="c1"># if isinstance(inputs, list) and all(isinstance(element, str) and &quot; &quot; not in element for element in inputs):</span>
        <span class="c1"># return [self._predict_one(sentence) for sentence in inputs]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">&quot;tokens&quot;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">})</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`SpanMarkerModel.predict` could not recognize your input. It accepts the following:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;* str: a string sentence.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;* List[str]: a pre-tokenized string sentence, i.e. a list of words.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;* List[str]: a list of multiple string sentences.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;* List[List[str]]: a list of multiple pre-tokenized string sentences, i.e. a list with lists of words.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;* Dataset: A  Dataset with `tokens` column and optionally `document_id` and `sentence_id` columns.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;    If the optional columns are provided, they will be used to provide document-level context.&quot;</span>
            <span class="p">)</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">})</span>
        <span class="n">num_inputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">))</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;tokens&quot;</span><span class="p">:</span> <span class="n">tokens</span><span class="p">,</span>
                <span class="s2">&quot;scores&quot;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s2">&quot;num_words&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>
        <span class="p">]</span>

        <span class="c1"># Tokenize &amp; add start/end markers</span>
        <span class="n">tokenizer_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;tokens&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]},</span> <span class="n">return_num_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_batch_encoding</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="n">batch_encoding</span> <span class="o">=</span> <span class="n">tokenizer_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_encoding&quot;</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tokenizer_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="c1"># Add context if possible</span>
        <span class="k">if</span> <span class="p">{</span><span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">}</span> <span class="o">&lt;=</span> <span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trained_with_document_context</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;This model was trained without document-level context: &quot;</span>
                    <span class="s2">&quot;inference with document-level context may cause decreased performance.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Add column to be able to revert sorting later</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;__sort_id&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)))</span>
            <span class="c1"># Sorting by doc ID and then sentence ID is required for add_context</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;document_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence_id&quot;</span><span class="p">])</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">Trainer</span><span class="o">.</span><span class="n">add_context</span><span class="p">(</span>
                <span class="n">dataset</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">max_prev_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_prev_context</span><span class="p">,</span>
                <span class="n">max_next_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_next_context</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="n">show_progress_bar</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;__sort_id&quot;</span><span class="p">])</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span><span class="s2">&quot;__sort_id&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trained_with_document_context</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;This model was trained with document-level context: &quot;</span>
                <span class="s2">&quot;inference without document-level context may cause decreased performance.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">show_progress_bar</span><span class="p">:</span>
            <span class="n">disable_progress_bar</span><span class="p">()</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">Trainer</span><span class="o">.</span><span class="n">spread_sample</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Spreading data between multiple samples&quot;</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model_max_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="s2">&quot;marker_max_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">marker_max_length</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">show_progress_bar</span><span class="p">:</span>
            <span class="n">enable_progress_bar</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch_start_idx</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">show_progress_bar</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_start_idx</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">batch_start_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">)))</span>
            <span class="c1"># Expanding the small tokenized output into full-scale input_ids, position_ids and attention_mask matrices.</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="c1"># Moving the inputs to the right device</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="c1"># Computing probabilities based on the logits</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Get the labels and the correponding probability scores</span>
            <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># TODO: Iterate over output.num_marker_pairs instead with enumerate</span>
            <span class="k">for</span> <span class="n">iter_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">num_marker_pairs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                <span class="n">input_id</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">][</span><span class="n">batch_start_idx</span> <span class="o">+</span> <span class="n">iter_idx</span><span class="p">]</span>
                <span class="n">num_marker_pairs</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">num_marker_pairs</span><span class="p">[</span><span class="n">iter_idx</span><span class="p">]</span>
                <span class="n">results</span><span class="p">[</span><span class="n">input_id</span><span class="p">][</span><span class="s2">&quot;scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">iter_idx</span><span class="p">,</span> <span class="p">:</span><span class="n">num_marker_pairs</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="n">results</span><span class="p">[</span><span class="n">input_id</span><span class="p">][</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">iter_idx</span><span class="p">,</span> <span class="p">:</span><span class="n">num_marker_pairs</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="n">results</span><span class="p">[</span><span class="n">input_id</span><span class="p">][</span><span class="s2">&quot;num_words&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">num_words</span><span class="p">[</span><span class="n">iter_idx</span><span class="p">]</span>

        <span class="n">all_entities</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">id2label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span>
        <span class="k">for</span> <span class="n">sample_idx</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span>
            <span class="n">num_words</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;num_words&quot;</span><span class="p">]</span>
            <span class="n">sentence</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>
            <span class="c1"># Get all of the valid spans to match with the score and labels</span>
            <span class="n">spans</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_all_valid_spans</span><span class="p">(</span><span class="n">num_words</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">entity_max_length</span><span class="p">))</span>

            <span class="n">word_selected</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_words</span>
            <span class="n">sentence_entities</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">word_start_index</span><span class="p">,</span> <span class="n">word_end_index</span><span class="p">),</span> <span class="n">score</span><span class="p">,</span> <span class="n">label_id</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">spans</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">label_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">outside_id</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">word_selected</span><span class="p">[</span><span class="n">word_start_index</span><span class="p">:</span><span class="n">word_end_index</span><span class="p">]):</span>
                    <span class="n">char_start_index</span> <span class="o">=</span> <span class="n">batch_encoding</span><span class="o">.</span><span class="n">word_to_chars</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">,</span> <span class="n">word_start_index</span><span class="p">)</span><span class="o">.</span><span class="n">start</span>
                    <span class="n">char_end_index</span> <span class="o">=</span> <span class="n">batch_encoding</span><span class="o">.</span><span class="n">word_to_chars</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">,</span> <span class="n">word_end_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">end</span>
                    <span class="n">entity</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s2">&quot;span&quot;</span><span class="p">:</span> <span class="n">sentence</span><span class="p">[</span><span class="n">char_start_index</span><span class="p">:</span><span class="n">char_end_index</span><span class="p">]</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                        <span class="k">else</span> <span class="n">sentence</span><span class="p">[</span><span class="n">word_start_index</span><span class="p">:</span><span class="n">word_end_index</span><span class="p">],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">id2label</span><span class="p">[</span><span class="n">label_id</span><span class="p">],</span>
                        <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                    <span class="p">}</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;char_start_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">char_start_index</span>
                        <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;char_end_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">char_end_index</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;word_start_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_start_index</span>
                        <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;word_end_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_end_index</span>
                    <span class="n">sentence_entities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entity</span><span class="p">)</span>

                    <span class="n">word_selected</span><span class="p">[</span><span class="n">word_start_index</span><span class="p">:</span><span class="n">word_end_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">word_end_index</span> <span class="o">-</span> <span class="n">word_start_index</span><span class="p">)</span>
            <span class="n">all_entities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">sorted</span><span class="p">(</span>
                    <span class="n">sentence_entities</span><span class="p">,</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">entity</span><span class="p">:</span> <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;char_start_index&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">entity</span><span class="p">[</span><span class="s2">&quot;word_start_index&quot;</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># if the input was a string or a list of tokens, return a list of dictionaries</span>
        <span class="k">if</span> <span class="n">single_input</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_entities</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_entities</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">all_entities</span></div>

<div class="viewcode-block" id="SpanMarkerModel.save_pretrained"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.save_pretrained">[docs]</a>    <span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span>
        <span class="n">is_main_process</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_function</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>
        <span class="n">push_to_hub</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_shard_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;10GB&quot;</span><span class="p">,</span>
        <span class="n">safe_serialization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">variant</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
            <span class="n">save_directory</span><span class="p">,</span>
            <span class="n">is_main_process</span><span class="o">=</span><span class="n">is_main_process</span><span class="p">,</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span>
            <span class="n">save_function</span><span class="o">=</span><span class="n">save_function</span><span class="p">,</span>
            <span class="n">push_to_hub</span><span class="o">=</span><span class="n">push_to_hub</span><span class="p">,</span>
            <span class="n">max_shard_size</span><span class="o">=</span><span class="n">max_shard_size</span><span class="p">,</span>
            <span class="n">safe_serialization</span><span class="o">=</span><span class="n">safe_serialization</span><span class="p">,</span>
            <span class="n">variant</span><span class="o">=</span><span class="n">variant</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
            <span class="n">save_directory</span><span class="p">,</span>
            <span class="n">is_main_process</span><span class="o">=</span><span class="n">is_main_process</span><span class="p">,</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span>
            <span class="n">save_function</span><span class="o">=</span><span class="n">save_function</span><span class="p">,</span>
            <span class="n">push_to_hub</span><span class="o">=</span><span class="n">push_to_hub</span><span class="p">,</span>
            <span class="n">max_shard_size</span><span class="o">=</span><span class="n">max_shard_size</span><span class="p">,</span>
            <span class="n">safe_serialization</span><span class="o">=</span><span class="n">safe_serialization</span><span class="p">,</span>
            <span class="n">variant</span><span class="o">=</span><span class="n">variant</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="s2">&quot;README.md&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">generate_model_card</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">))</span></div>

<div class="viewcode-block" id="SpanMarkerModel.try_cuda"><a class="viewcode-back" href="../../api/span_marker.modeling.html#span_marker.modeling.SpanMarkerModel.try_cuda">[docs]</a>    <span class="k">def</span> <span class="nf">try_cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Try to moves all model parameters and buffers to the GPU, do nothing if failed.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method modifies the module in-place.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be</span>
<span class="sd">                copied to that device</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">AssertionError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span></div></div>
</pre></div>

        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            

            
        </ul>

        
            <div id="copyright">
                &copy; 2023, Tom Aarsen
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>